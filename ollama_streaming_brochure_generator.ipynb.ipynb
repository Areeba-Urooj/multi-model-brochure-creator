{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24936ddd-9602-42f6-a699-7e6fe6c40ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200ffa7c-8ffa-47c2-8292-5a4a969e14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629036f3-7bc4-4743-b384-adeab1d21384",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c78d0e-2262-4e15-9e56-6e9d500b1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chat(message, model=\"llama3.2\"):\n",
    "    \"\"\"Simple chat completion with Ollama local model\"\"\"\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": message}\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": 0.7,\n",
    "                \"num_predict\": 1000  # Ollama uses num_predict instead of max_tokens\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(OLLAMA_API, headers=HEADERS, json=payload)\n",
    "        response.raise_for_status()  # Raises an exception for bad status codes\n",
    "        \n",
    "        result = response.json()\n",
    "        return result[\"message\"][\"content\"]\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Network Error: {str(e)}\"\n",
    "    except KeyError as e:\n",
    "        return f\"Response format error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82921cbe-cb56-453c-bb9d-ff70caf08535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1940c6f6-6545-46ea-b3ab-68001eeddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffbc806-7b5e-4952-a427-a5cd9f969f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://news.ycombinator.com',\n",
       " 'https://nebula.io/?utm_source=ed&utm_medium=referral',\n",
       " 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html',\n",
       " 'https://patents.google.com/patent/US20210049536A1/',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/',\n",
       " 'https://edwarddonner.com/',\n",
       " 'https://edwarddonner.com/connect-four/',\n",
       " 'https://edwarddonner.com/outsmart/',\n",
       " 'https://edwarddonner.com/about-me-and-about-nebula/',\n",
       " 'https://edwarddonner.com/posts/',\n",
       " 'mailto:hello@mygroovydomain.com',\n",
       " 'https://www.linkedin.com/in/eddonner/',\n",
       " 'https://twitter.com/edwarddonner',\n",
       " 'https://www.facebook.com/edward.donner.52']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "ed.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1d1252-eb2b-454a-9276-16df404fb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize function for Ollama \n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    user_message = user_prompt_for(website)  # Using the user_prompt_for function\n",
    "     # Using simple_chat function with Ollama\n",
    "    response = simple_chat(user_message)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d143563b-ceae-48ec-8f39-6c77b6d3a626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Google Website Summary\n",
       "\n",
       "## Overview\n",
       "\n",
       "The Google website provides various services and features, including:\n",
       "\n",
       "* **Gmail**: a popular email service\n",
       "* **Images**: a search engine for images\n",
       "* **Advertising**, **Business**, and **How Search works**: sections detailing Google's advertising policies, business offerings, and how its search algorithm works\n",
       "\n",
       "## News/Announcements\n",
       "\n",
       "Unfortunately, there are no news or announcements on this website. It appears to be a collection of services and features rather than a platform for sharing updates.\n",
       "\n",
       "## Language Options\n",
       "\n",
       "The website offers translations in **اردو**, **پښتو**, and **سنڌي** (Urdu, Pashto, and Sindhi), catering to users from various regions.\n",
       "\n",
       "## Other Notable Features\n",
       "\n",
       "* The website has **Settings** and **Privacy** sections, allowing users to manage their account settings and data protection.\n",
       "* Users can also access their **Search history**, **Send feedback**, and **Dark theme** preferences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it\n",
    "result = summarize(\"https://www.google.com\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3c2842-ac4c-426e-84b2-3cb0d05dafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7996d29e-2d5b-40a6-9c8e-4b0113433e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "You should respond in JSON as in this example:\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9517ff-3152-4c65-b08a-6f06e7b03d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6556a85b-8261-4655-aebe-42a25f799e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "https://edwarddonner.com/\n",
      "https://news.ycombinator.com\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/\n",
      "https://edwarddonner.com/connect-four/\n",
      "https://edwarddonner.com/outsmart/\n",
      "https://edwarddonner.com/about-me-and-about-nebula/\n",
      "https://edwarddonner.com/posts/\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://www.facebook.com/edward.donner.52\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18c80d6d-c752-428c-bb68-85a865f7694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    # Make request to local Ollama instead of OpenAI\n",
    "    response = requests.post('http://localhost:11434/api/generate',\n",
    "                           json={\n",
    "                               'model': 'llama3.2',  # or whatever model you have\n",
    "                               'prompt': f\"\"\"System: You are a helpful assistant that extracts links from website content.\n",
    "\n",
    "User: Please extract all links from this website content: {get_links_user_prompt(website)}\n",
    "\n",
    "Return as JSON format: {{\"links\": [...]}}\"\"\",\n",
    "                               'stream': False,\n",
    "                               'format': 'json'\n",
    "                           })\n",
    "    \n",
    "    result = response.json()\n",
    "    try:\n",
    "        parsed_result = json.loads(result['response'])\n",
    "        return parsed_result\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing JSON:\", result['response'])\n",
    "        return {\"links\": []}  # Return empty structure on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7294044c-d1ff-4e5f-8663-56a8b81cb615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/docs',\n",
       " '/enterprise',\n",
       " '/pricing',\n",
       " '/login',\n",
       " '/join',\n",
       " '/spaces',\n",
       " '/models',\n",
       " '/nanonets/Nanonets-OCR-s',\n",
       " '/mistralai/Magistral-Small-2506',\n",
       " '/echo840/MonkeyOCR',\n",
       " '/tencent/Hunyuan3D-2.1',\n",
       " '/Menlo/Jan-nano',\n",
       " '/models',\n",
       " '/spaces/enzostvs/deepsite',\n",
       " '/spaces/aisheets/sheets',\n",
       " '/spaces/ilcve21/Sparc3D',\n",
       " '/spaces/ResembleAI/Chatterbox',\n",
       " '/spaces/multimodalart/wan2-1-fast',\n",
       " '/spaces',\n",
       " '/datasets/nvidia/Nemotron-Personas',\n",
       " '/datasets/institutional/institutional-books-1.0',\n",
       " '/datasets/fka/awesome-chatgpt-prompts',\n",
       " '/datasets/open-thoughts/OpenThoughts3-1.2M',\n",
       " '/datasets/miriad/miriad-5.8M',\n",
       " '/datasets',\n",
       " '/join',\n",
       " '/pricing#endpoints',\n",
       " '/pricing#spaces',\n",
       " '/pricing',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/enterprise',\n",
       " '/allenai',\n",
       " '/facebook',\n",
       " '/amazon',\n",
       " '/google',\n",
       " '/Intel',\n",
       " '/microsoft',\n",
       " '/grammarly',\n",
       " '/Writer',\n",
       " '/docs/transformers',\n",
       " '/docs/diffusers',\n",
       " '/docs/safetensors',\n",
       " '/docs/huggingface_hub',\n",
       " '/docs/tokenizers',\n",
       " '/docs/trl',\n",
       " '/docs/transformers.js',\n",
       " '/docs/smolagents',\n",
       " '/docs/peft',\n",
       " '/docs/datasets',\n",
       " '/docs/text-generation-inference',\n",
       " '/docs/accelerate',\n",
       " '/models',\n",
       " '/datasets',\n",
       " '/spaces',\n",
       " '/changelog',\n",
       " 'https://endpoints.huggingface.co',\n",
       " '/chat',\n",
       " '/huggingface',\n",
       " '/brand',\n",
       " '/terms-of-service',\n",
       " '/privacy',\n",
       " 'https://apply.workable.com/huggingface/',\n",
       " 'mailto:press@huggingface.co',\n",
       " '/learn',\n",
       " '/docs',\n",
       " '/blog',\n",
       " 'https://discuss.huggingface.co',\n",
       " 'https://status.huggingface.co/',\n",
       " 'https://github.com/huggingface',\n",
       " 'https://twitter.com/huggingface',\n",
       " 'https://www.linkedin.com/company/huggingface/',\n",
       " '/join/discord',\n",
       " 'https://www.zhihu.com/org/huggingface',\n",
       " 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/chinese-language-blog/wechat.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
    "\n",
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1321bfae-f4f1-46f9-997d-f6fabc6ac7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': ['https://endpoints.huggingface.co',\n",
       "  'https://discuss.huggingface.co',\n",
       "  'https://status.huggingface.co/',\n",
       "  'https://github.com/huggingface',\n",
       "  'https://twitter.com/huggingface',\n",
       "  'https://www.linkedin.com/company/huggingface/',\n",
       "  'https://join.discord.com',\n",
       "  'https://www.zhihu.com/org/huggingface']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "062ab5af-0341-4d68-99ad-ab1766e53d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\nLink: {link}\\n\"\n",
    "        result += Website(link).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07794807-3146-4b8d-9939-3054135585fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': ['https://huggingface.co/docs/transformers', 'https://huggingface.co/docs/diffusers', 'https://huggingface.co/docs/safetensors', 'https://huggingface.co/docs/huggingface_hub', 'https://huggingface.co/docs/tokenizers', 'https://huggingface.co/docs/trl', 'https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/pricing', 'https://huggingface.co/enterprise', 'https://huggingface.co/allenai', 'https://huggingface.co/facebook', 'https://huggingface.co/amazon', 'https://huggingface.co/google', 'https://huggingface.co/Intel', 'https://huggingface.co/microsoft', 'https://huggingface.co/grammarly', 'https://huggingface.co/Writer']}\n",
      "Landing page:\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "nanonets/Nanonets-OCR-s\n",
      "Updated\n",
      "about 21 hours ago\n",
      "•\n",
      "7.96k\n",
      "•\n",
      "535\n",
      "mistralai/Magistral-Small-2506\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "13.5k\n",
      "•\n",
      "460\n",
      "echo840/MonkeyOCR\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "4\n",
      "•\n",
      "351\n",
      "tencent/Hunyuan3D-2.1\n",
      "Updated\n",
      "about 22 hours ago\n",
      "•\n",
      "2.75k\n",
      "•\n",
      "272\n",
      "Menlo/Jan-nano\n",
      "Updated\n",
      "about 3 hours ago\n",
      "•\n",
      "3.29k\n",
      "•\n",
      "168\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "Running\n",
      "8.14k\n",
      "8.14k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "Running\n",
      "224\n",
      "224\n",
      "Sheets\n",
      "🗂\n",
      "Convert ideas into structured datasets\n",
      "Running\n",
      "203\n",
      "203\n",
      "Sparc3D\n",
      "🏃\n",
      "Next-Gen High-Resolution 3D Model Generation\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "1.1k\n",
      "1.1k\n",
      "Chatterbox TTS\n",
      "🍿\n",
      "Expressive Zeroshot TTS\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "740\n",
      "740\n",
      "Wan2.1 Fast\n",
      "🎥\n",
      "Generate a video animation from an image\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "nvidia/Nemotron-Personas\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "8.82k\n",
      "•\n",
      "116\n",
      "institutional/institutional-books-1.0\n",
      "Updated\n",
      "about 15 hours ago\n",
      "•\n",
      "2.98k\n",
      "•\n",
      "89\n",
      "fka/awesome-chatgpt-prompts\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "21.7k\n",
      "•\n",
      "7.94k\n",
      "open-thoughts/OpenThoughts3-1.2M\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "15.6k\n",
      "•\n",
      "104\n",
      "miriad/miriad-5.8M\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "1.8k\n",
      "•\n",
      "37\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "•\n",
      "765 models\n",
      "•\n",
      "3.44k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.17k models\n",
      "•\n",
      "6.46k followers\n",
      "Amazon\n",
      "company\n",
      "•\n",
      "20 models\n",
      "•\n",
      "3.24k followers\n",
      "Google\n",
      "company\n",
      "•\n",
      "1k models\n",
      "•\n",
      "16.8k followers\n",
      "Intel\n",
      "company\n",
      "•\n",
      "232 models\n",
      "•\n",
      "2.64k followers\n",
      "Microsoft\n",
      "company\n",
      "•\n",
      "390 models\n",
      "•\n",
      "13k followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "164 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "296 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "145,686\n",
      "State-of-the-art ML for PyTorch, TensorFlow, JAX\n",
      "Diffusers\n",
      "29,377\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,309\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "2,690\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "9,801\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "14,202\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "13,815\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "20,206\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "18,784\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,271\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,227\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "8,839\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/transformers\n",
      "Webpage Title:\n",
      "Transformers\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Transformers documentation\n",
      "Transformers\n",
      "Transformers\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v4.52.3\n",
      "v4.51.3\n",
      "v4.50.0\n",
      "v4.49.0\n",
      "v4.48.2\n",
      "v4.47.1\n",
      "v4.46.3\n",
      "v4.45.2\n",
      "v4.44.2\n",
      "v4.43.4\n",
      "v4.42.4\n",
      "v4.41.2\n",
      "v4.40.2\n",
      "v4.39.3\n",
      "v4.38.2\n",
      "v4.37.2\n",
      "v4.36.1\n",
      "v4.35.2\n",
      "v4.34.1\n",
      "v4.33.3\n",
      "v4.32.1\n",
      "v4.31.0\n",
      "v4.30.0\n",
      "v4.29.1\n",
      "v4.28.1\n",
      "v4.27.2\n",
      "v4.26.1\n",
      "v4.25.1\n",
      "v4.24.0\n",
      "v4.23.1\n",
      "v4.22.2\n",
      "v4.21.3\n",
      "v4.20.1\n",
      "v4.19.4\n",
      "v4.18.0\n",
      "v4.17.0\n",
      "v4.16.2\n",
      "v4.15.0\n",
      "v4.14.1\n",
      "v4.13.0\n",
      "v4.12.5\n",
      "v4.11.3\n",
      "v4.10.1\n",
      "v4.9.2\n",
      "v4.8.2\n",
      "v4.7.0\n",
      "v4.6.0\n",
      "v4.5.1\n",
      "v4.4.2\n",
      "v4.3.3\n",
      "v4.2.2\n",
      "v4.1.1\n",
      "v4.0.1\n",
      "v3.5.1\n",
      "v3.4.0\n",
      "v3.3.1\n",
      "v3.2.0\n",
      "v3.1.0\n",
      "v3.0.2\n",
      "v2.11.0\n",
      "v2.10.0\n",
      "v2.9.1\n",
      "v2.8.0\n",
      "v2.7.0\n",
      "v2.6.0\n",
      "v2.5.1\n",
      "v2.4.1\n",
      "v2.3.0\n",
      "v2.2.2\n",
      "v2.1.1\n",
      "v2.0.0\n",
      "v1.2.0\n",
      "v1.1.0\n",
      "v1.0.0\n",
      "doc-builder-html\n",
      "AR\n",
      "DE\n",
      "EN\n",
      "ES\n",
      "FR\n",
      "HI\n",
      "IT\n",
      "JA\n",
      "KO\n",
      "PT\n",
      "TE\n",
      "TR\n",
      "ZH\n",
      "Get started\n",
      "Transformers\n",
      "Installation\n",
      "Quickstart\n",
      "Base classes\n",
      "Inference\n",
      "Training\n",
      "Quantization\n",
      "Export to production\n",
      "Resources\n",
      "Contribute\n",
      "API\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Transformers\n",
      "Transformers is a library of pretrained natural language processing, computer vision, audio, and multimodal models for inference and training. Use Transformers to train models on your data, build inference applications, and generate text with large language models.\n",
      "Explore the\n",
      "Hugging Face Hub\n",
      "today to find a model and use Transformers to help you get started right away.\n",
      "Features\n",
      "Transformers provides everything you need for inference or training with state-of-the-art pretrained models. Some of the main features include:\n",
      "Pipeline\n",
      ": Simple and optimized inference class for many machine learning tasks like text generation, image segmentation, automatic speech recognition, document question answering, and more.\n",
      "Trainer\n",
      ": A comprehensive trainer that supports features such as mixed precision, torch.compile, and FlashAttention for training and distributed training for PyTorch models.\n",
      "generate\n",
      ": Fast text generation with large language models (LLMs) and vision language models (VLMs), including support for streaming and multiple decoding strategies.\n",
      "Design\n",
      "Read our\n",
      "Philosophy\n",
      "to learn more about Transformers’ design principles.\n",
      "Transformers is designed for developers and machine learning engineers and researchers. Its main design principles are:\n",
      "Fast and easy to use: Every model is implemented from only three main classes (configuration, model, and preprocessor) and can be quickly used for inference or training with\n",
      "Pipeline\n",
      "or\n",
      "Trainer\n",
      ".\n",
      "Pretrained models: Reduce your carbon footprint, compute cost and time by using a pretrained model instead of training an entirely new one. Each pretrained model is reproduced as closely as possible to the original model and offers state-of-the-art performance.\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Installation\n",
      "→\n",
      "Transformers\n",
      "Features\n",
      "Design\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/diffusers\n",
      "Webpage Title:\n",
      "Diffusers\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Diffusers documentation\n",
      "Diffusers\n",
      "Diffusers\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.33.1\n",
      "v0.32.2\n",
      "v0.31.0\n",
      "v0.30.3\n",
      "v0.29.2\n",
      "v0.28.2\n",
      "v0.27.2\n",
      "v0.26.3\n",
      "v0.25.1\n",
      "v0.24.0\n",
      "v0.23.1\n",
      "v0.22.3\n",
      "v0.21.0\n",
      "v0.20.0\n",
      "v0.19.3\n",
      "v0.18.2\n",
      "v0.17.1\n",
      "v0.16.0\n",
      "v0.15.0\n",
      "v0.14.0\n",
      "v0.13.0\n",
      "v0.12.0\n",
      "v0.11.0\n",
      "v0.10.2\n",
      "v0.9.0\n",
      "v0.8.0\n",
      "v0.7.0\n",
      "v0.6.0\n",
      "v0.5.1\n",
      "v0.4.1\n",
      "v0.3.0\n",
      "v0.2.4\n",
      "EN\n",
      "JA\n",
      "KO\n",
      "PT\n",
      "ZH\n",
      "Get started\n",
      "🧨 Diffusers\n",
      "Quicktour\n",
      "Effective and efficient diffusion\n",
      "Installation\n",
      "Tutorials\n",
      "Overview\n",
      "Understanding pipelines, models and schedulers\n",
      "AutoPipeline\n",
      "Train a diffusion model\n",
      "Load LoRAs for inference\n",
      "Accelerate inference of text-to-image diffusion models\n",
      "Working with big models\n",
      "Load pipelines and adapters\n",
      "Load pipelines\n",
      "Load community pipelines and components\n",
      "Load schedulers and models\n",
      "Model files and layouts\n",
      "Load adapters\n",
      "Push files to the Hub\n",
      "Generative tasks\n",
      "Unconditional image generation\n",
      "Text-to-image\n",
      "Image-to-image\n",
      "Inpainting\n",
      "Video generation\n",
      "Depth-to-image\n",
      "Inference techniques\n",
      "Overview\n",
      "Create a server\n",
      "Distributed inference\n",
      "Merge LoRAs\n",
      "Scheduler features\n",
      "Pipeline callbacks\n",
      "Reproducible pipelines\n",
      "Controlling image quality\n",
      "Prompt techniques\n",
      "Advanced inference\n",
      "Outpainting\n",
      "Hybrid Inference\n",
      "Overview\n",
      "VAE Decode\n",
      "VAE Encode\n",
      "API Reference\n",
      "Specific pipeline examples\n",
      "CogVideoX\n",
      "ConsisID\n",
      "Stable Diffusion XL\n",
      "SDXL Turbo\n",
      "Kandinsky\n",
      "IP-Adapter\n",
      "OmniGen\n",
      "PAG\n",
      "ControlNet\n",
      "T2I-Adapter\n",
      "Latent Consistency Model\n",
      "Textual inversion\n",
      "Shap-E\n",
      "DiffEdit\n",
      "Trajectory Consistency Distillation-LoRA\n",
      "Stable Video Diffusion\n",
      "Marigold Computer Vision\n",
      "Training\n",
      "Overview\n",
      "Create a dataset for training\n",
      "Adapt a model to a new task\n",
      "Models\n",
      "Methods\n",
      "Quantization Methods\n",
      "Getting Started\n",
      "bitsandbytes\n",
      "gguf\n",
      "torchao\n",
      "quanto\n",
      "Accelerate inference and reduce memory\n",
      "Speed up inference\n",
      "Reduce memory usage\n",
      "PyTorch 2.0\n",
      "xFormers\n",
      "Token merging\n",
      "DeepCache\n",
      "TGATE\n",
      "xDiT\n",
      "ParaAttention\n",
      "Optimized model formats\n",
      "JAX/Flax\n",
      "ONNX\n",
      "OpenVINO\n",
      "Core ML\n",
      "Optimized hardware\n",
      "Metal Performance Shaders (MPS)\n",
      "Habana Gaudi\n",
      "AWS Neuron\n",
      "Conceptual Guides\n",
      "Philosophy\n",
      "Controlled generation\n",
      "How to contribute?\n",
      "Diffusers' Ethical Guidelines\n",
      "Evaluating Diffusion Models\n",
      "Community Projects\n",
      "Projects built with Diffusers\n",
      "API\n",
      "Main Classes\n",
      "Loaders\n",
      "Models\n",
      "Pipelines\n",
      "Schedulers\n",
      "Internal classes\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Diffusers\n",
      "🤗 Diffusers is the go-to library for state-of-the-art pretrained diffusion models for generating images, audio, and even 3D structures of molecules. Whether you’re looking for a simple inference solution or want to train your own diffusion model, 🤗 Diffusers is a modular toolbox that supports both. Our library is designed with a focus on\n",
      "usability over performance\n",
      ",\n",
      "simple over easy\n",
      ", and\n",
      "customizability over abstractions\n",
      ".\n",
      "The library has three main components:\n",
      "State-of-the-art diffusion pipelines for inference with just a few lines of code. There are many pipelines in 🤗 Diffusers, check out the table in the pipeline\n",
      "overview\n",
      "for a complete list of available pipelines and the task they solve.\n",
      "Interchangeable\n",
      "noise schedulers\n",
      "for balancing trade-offs between generation speed and quality.\n",
      "Pretrained\n",
      "models\n",
      "that can be used as building blocks, and combined with schedulers, for creating your own end-to-end diffusion systems.\n",
      "Tutorials\n",
      "Learn the fundamental skills you need to start generating outputs, build your own diffusion system, and train a diffusion model. We recommend starting here if you're using 🤗 Diffusers for the first time!\n",
      "How-to guides\n",
      "Practical guides for helping you load pipelines, models, and schedulers. You'll also learn how to use pipelines for specific tasks, control how outputs are generated, optimize for inference speed, and different training techniques.\n",
      "Conceptual guides\n",
      "Understand why the library was designed the way it was, and learn more about the ethical guidelines and safety implementations for using the library.\n",
      "Reference\n",
      "Technical descriptions of how 🤗 Diffusers classes and methods work.\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Quicktour\n",
      "→\n",
      "Diffusers\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/safetensors\n",
      "Webpage Title:\n",
      "Safetensors\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Safetensors documentation\n",
      "Safetensors\n",
      "Safetensors\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.5.0-rc.0\n",
      "v0.3.2\n",
      "v0.2.9\n",
      "EN\n",
      "Getting started\n",
      "🤗 Safetensors\n",
      "Speed Comparison\n",
      "Tensor Sharing in Pytorch\n",
      "Metadata Parsing\n",
      "Convert weights to safetensors\n",
      "API\n",
      "Torch API\n",
      "Tensorflow API\n",
      "PaddlePaddle API\n",
      "Flax API\n",
      "Numpy API\n",
      "You are viewing\n",
      "main\n",
      "version, which requires\n",
      "installation from source\n",
      ". If you'd like\n",
      "\t\t\tregular pip install, checkout the latest stable version (\n",
      "v0.5.0-rc.0\n",
      ").\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Safetensors\n",
      "Safetensors is a new simple format for storing tensors safely (as opposed to pickle) and that is still fast (zero-copy). Safetensors is really\n",
      "fast 🚀\n",
      ".\n",
      "Installation\n",
      "with pip:\n",
      "Copied\n",
      "pip\n",
      "install\n",
      "safetensors\n",
      "with conda:\n",
      "Copied\n",
      "conda\n",
      "install\n",
      "-c huggingface safetensors\n",
      "Usage\n",
      "Load tensors\n",
      "Copied\n",
      "from\n",
      "safetensors\n",
      "import\n",
      "safe_open\n",
      "\n",
      "tensors = {}\n",
      "with\n",
      "safe_open(\n",
      "\"model.safetensors\"\n",
      ", framework=\n",
      "\"pt\"\n",
      ", device=\n",
      "0\n",
      ")\n",
      "as\n",
      "f:\n",
      "for\n",
      "k\n",
      "in\n",
      "f.keys():\n",
      "        tensors[k] = f.get_tensor(k)\n",
      "Loading only part of the tensors (interesting when running on multiple GPU)\n",
      "Copied\n",
      "from\n",
      "safetensors\n",
      "import\n",
      "safe_open\n",
      "\n",
      "tensors = {}\n",
      "with\n",
      "safe_open(\n",
      "\"model.safetensors\"\n",
      ", framework=\n",
      "\"pt\"\n",
      ", device=\n",
      "0\n",
      ")\n",
      "as\n",
      "f:\n",
      "    tensor_slice = f.get_slice(\n",
      "\"embedding\"\n",
      ")\n",
      "    vocab_size, hidden_dim = tensor_slice.get_shape()\n",
      "    tensor = tensor_slice[:, :hidden_dim]\n",
      "Save tensors\n",
      "Copied\n",
      "import\n",
      "torch\n",
      "from\n",
      "safetensors.torch\n",
      "import\n",
      "save_file\n",
      "\n",
      "tensors = {\n",
      "\"embedding\"\n",
      ": torch.zeros((\n",
      "2\n",
      ",\n",
      "2\n",
      ")),\n",
      "\"attention\"\n",
      ": torch.zeros((\n",
      "2\n",
      ",\n",
      "3\n",
      "))\n",
      "}\n",
      "save_file(tensors,\n",
      "\"model.safetensors\"\n",
      ")\n",
      "Format\n",
      "Let’s say you have safetensors file named\n",
      "model.safetensors\n",
      ", then\n",
      "model.safetensors\n",
      "will have the following internal format:\n",
      "Featured Projects\n",
      "Safetensors is being used widely at leading AI enterprises, such as\n",
      "Hugging Face\n",
      ",\n",
      "EleutherAI\n",
      ", and\n",
      "StabilityAI\n",
      ". Here is a non-exhaustive list of projects that are using safetensors:\n",
      "huggingface/transformers\n",
      "ml-explore/mlx\n",
      "huggingface/candle\n",
      "AUTOMATIC1111/stable-diffusion-webui\n",
      "Llama-cpp\n",
      "microsoft/TaskMatrix\n",
      "hpcaitech/ColossalAI\n",
      "huggingface/pytorch-image-models\n",
      "CivitAI\n",
      "huggingface/diffusers\n",
      "coreylowman/dfdx\n",
      "invoke-ai/InvokeAI\n",
      "oobabooga/text-generation-webui\n",
      "Sanster/lama-cleaner\n",
      "PaddlePaddle/PaddleNLP\n",
      "AIGC-Audio/AudioGPT\n",
      "brycedrennan/imaginAIry\n",
      "comfyanonymous/ComfyUI\n",
      "LianjiaTech/BELLE\n",
      "alvarobartt/safejax\n",
      "MaartenGr/BERTopic\n",
      "rachthree/safestructures\n",
      "justinchuby/onnx-safetensors\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Speed Comparison\n",
      "→\n",
      "Safetensors\n",
      "Installation\n",
      "Usage\n",
      "Load tensors\n",
      "Save tensors\n",
      "Format\n",
      "Featured\n",
      "Projects\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/huggingface_hub\n",
      "Webpage Title:\n",
      "🤗 Hub client library\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Hub Python Library documentation\n",
      "🤗 Hub client library\n",
      "Hub Python Library\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.33.0\n",
      "v0.32.6\n",
      "v0.31.4\n",
      "v0.30.2\n",
      "v0.29.3\n",
      "v0.28.1\n",
      "v0.27.1\n",
      "v0.26.5\n",
      "v0.25.2\n",
      "v0.24.7\n",
      "v0.23.5\n",
      "v0.22.2\n",
      "v0.21.4\n",
      "v0.20.3\n",
      "v0.19.3\n",
      "v0.18.0.rc0\n",
      "v0.17.3\n",
      "v0.16.3\n",
      "v0.15.1\n",
      "v0.14.1\n",
      "v0.13.4\n",
      "v0.12.1\n",
      "v0.11.0\n",
      "v0.10.1\n",
      "v0.9.1\n",
      "v0.8.1\n",
      "v0.7.0.rc0\n",
      "v0.6.0.rc0\n",
      "v0.5.1\n",
      "CN\n",
      "DE\n",
      "EN\n",
      "FR\n",
      "HI\n",
      "KO\n",
      "TM\n",
      "Get started\n",
      "Home\n",
      "Quickstart\n",
      "Installation\n",
      "How-to guides\n",
      "Overview\n",
      "Download files\n",
      "Upload files\n",
      "Use the CLI\n",
      "HfFileSystem\n",
      "Repository\n",
      "Search\n",
      "Inference\n",
      "Inference Endpoints\n",
      "Community Tab\n",
      "Collections\n",
      "Cache\n",
      "Model Cards\n",
      "Manage your Space\n",
      "Integrate a library\n",
      "Webhooks\n",
      "Conceptual guides\n",
      "Git vs HTTP paradigm\n",
      "Reference\n",
      "Overview\n",
      "Authentication\n",
      "Environment variables\n",
      "Managing local and online repositories\n",
      "Hugging Face Hub API\n",
      "Downloading files\n",
      "Mixins & serialization methods\n",
      "Inference Types\n",
      "Inference Client\n",
      "Inference Endpoints\n",
      "MCP Client\n",
      "HfFileSystem\n",
      "Utilities\n",
      "Discussions and Pull Requests\n",
      "Cache-system reference\n",
      "Repo Cards and Repo Card Data\n",
      "Space runtime\n",
      "Collections\n",
      "TensorBoard logger\n",
      "Webhooks server\n",
      "Serialization\n",
      "Strict dataclasses\n",
      "OAuth\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "🤗 Hub client library\n",
      "The\n",
      "huggingface_hub\n",
      "library allows you to interact with the\n",
      "Hugging Face\n",
      "Hub\n",
      ", a machine learning platform for creators and collaborators.\n",
      "Discover pre-trained models and datasets for your projects or play with the hundreds of\n",
      "machine learning apps hosted on the Hub. You can also create and share your own models\n",
      "and datasets with the community. The\n",
      "huggingface_hub\n",
      "library provides a simple way to\n",
      "do all these things with Python.\n",
      "Read the\n",
      "quick start guide\n",
      "to get up and running with the\n",
      "huggingface_hub\n",
      "library. You will learn how to download files from the Hub, create a\n",
      "repository, and upload files to the Hub. Keep reading to learn more about how to manage\n",
      "your repositories on the 🤗 Hub, how to interact in discussions or even how to access\n",
      "the Inference API.\n",
      "How-to guides\n",
      "Practical guides to help you achieve a specific goal. Take a look at these guides to learn how to use huggingface_hub to solve real-world problems.\n",
      "Reference\n",
      "Exhaustive and technical description of huggingface_hub classes and methods.\n",
      "Conceptual guides\n",
      "High-level explanations for building a better understanding of huggingface_hub philosophy.\n",
      "Contribute\n",
      "All contributions to the\n",
      "huggingface_hub\n",
      "are welcomed and equally valued! 🤗 Besides\n",
      "adding or fixing existing issues in the code, you can also help improve the\n",
      "documentation by making sure it is accurate and up-to-date, help answer questions on\n",
      "issues, and request new features you think will improve the library. Take a look at the\n",
      "contribution\n",
      "guide\n",
      "to\n",
      "learn more about how to submit a new issue or feature request, how to submit a pull\n",
      "request, and how to test your contributions to make sure everything works as expected.\n",
      "Contributors should also be respectful of our\n",
      "code of\n",
      "conduct\n",
      "to\n",
      "create an inclusive and welcoming collaborative space for everyone.\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Quickstart\n",
      "→\n",
      "🤗\n",
      "Hub client library\n",
      "Contribute\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/tokenizers\n",
      "Webpage Title:\n",
      "Tokenizers\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Tokenizers documentation\n",
      "Tokenizers\n",
      "Tokenizers\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.20.3\n",
      "v0.13.4.rc2\n",
      "v0.10.0\n",
      "v0.9.4\n",
      "EN\n",
      "Getting started\n",
      "🤗 Tokenizers\n",
      "Quicktour\n",
      "Installation\n",
      "The tokenization pipeline\n",
      "Components\n",
      "Training from memory\n",
      "API\n",
      "Input Sequences\n",
      "Encode Inputs\n",
      "Tokenizer\n",
      "Encoding\n",
      "Added Tokens\n",
      "Models\n",
      "Normalizers\n",
      "Pre-tokenizers\n",
      "Post-processors\n",
      "Trainers\n",
      "Decoders\n",
      "Visualizer\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "Tokenizers\n",
      "Fast State-of-the-art tokenizers, optimized for both research and\n",
      "production\n",
      "🤗 Tokenizers\n",
      "provides an\n",
      "implementation of today’s most used tokenizers, with a focus on\n",
      "performance and versatility. These tokenizers are also used in\n",
      "🤗 Transformers\n",
      ".\n",
      "Main features:\n",
      "Train new vocabularies and tokenize, using today’s most used tokenizers.\n",
      "Extremely fast (both training and tokenization), thanks to the Rust implementation. Takes less than 20 seconds to tokenize a GB of text on a server’s CPU.\n",
      "Easy to use, but also extremely versatile.\n",
      "Designed for both research and production.\n",
      "Full alignment tracking. Even with destructive normalization, it’s always possible to get the part of the original sentence that corresponds to any token.\n",
      "Does all the pre-processing: Truncation, Padding, add the special tokens your model needs.\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Quicktour\n",
      "→\n",
      "Tokenizers\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/docs/trl\n",
      "Webpage Title:\n",
      "TRL - Transformer Reinforcement Learning\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "TRL documentation\n",
      "TRL - Transformer Reinforcement Learning\n",
      "TRL\n",
      "🏡 View all docs\n",
      "AWS Trainium & Inferentia\n",
      "Accelerate\n",
      "Amazon SageMaker\n",
      "Argilla\n",
      "AutoTrain\n",
      "Bitsandbytes\n",
      "Chat UI\n",
      "Dataset viewer\n",
      "Datasets\n",
      "Diffusers\n",
      "Distilabel\n",
      "Evaluate\n",
      "Gradio\n",
      "Hub\n",
      "Hub Python Library\n",
      "Huggingface.js\n",
      "Inference Endpoints (dedicated)\n",
      "Inference Providers\n",
      "LeRobot\n",
      "Leaderboards\n",
      "Lighteval\n",
      "Optimum\n",
      "PEFT\n",
      "Safetensors\n",
      "Sentence Transformers\n",
      "TRL\n",
      "Tasks\n",
      "Text Embeddings Inference\n",
      "Text Generation Inference\n",
      "Tokenizers\n",
      "Transformers\n",
      "Transformers.js\n",
      "smolagents\n",
      "timm\n",
      "Search documentation\n",
      "main\n",
      "v0.18.1\n",
      "v0.17.0\n",
      "v0.16.1\n",
      "v0.15.2\n",
      "v0.14.0\n",
      "v0.13.0\n",
      "v0.12.2\n",
      "v0.11.4\n",
      "v0.10.1\n",
      "v0.9.6\n",
      "v0.8.6\n",
      "v0.7.11\n",
      "v0.6.0\n",
      "v0.5.0\n",
      "v0.4.7\n",
      "v0.3.1\n",
      "v0.2.1\n",
      "v0.1.1\n",
      "EN\n",
      "Getting started\n",
      "TRL\n",
      "Installation\n",
      "Quickstart\n",
      "Conceptual Guides\n",
      "Dataset Formats\n",
      "Training FAQ\n",
      "Understanding Logs\n",
      "How-to guides\n",
      "Command Line Interface (CLI)\n",
      "Customizing the Training\n",
      "Reducing Memory Usage\n",
      "Speeding Up Training\n",
      "Distributing Training\n",
      "Using Trained Models\n",
      "Integrations\n",
      "DeepSpeed\n",
      "Liger Kernel\n",
      "PEFT\n",
      "Unsloth\n",
      "vLLM\n",
      "Examples\n",
      "Example Overview\n",
      "Community Tutorials\n",
      "Sentiment Tuning\n",
      "Training StackLlama\n",
      "Detoxifying a Language Model\n",
      "Multi Adapter RLHF\n",
      "Fine-tuning a Multimodal Model Using SFT (Single or Multi-Image Dataset)\n",
      "API\n",
      "Trainers\n",
      "AlignProp\n",
      "BCO\n",
      "CPO\n",
      "DDPO\n",
      "DPO\n",
      "Online DPO\n",
      "GKD\n",
      "GRPO\n",
      "KTO\n",
      "Nash-MD\n",
      "ORPO\n",
      "PPO\n",
      "PRM\n",
      "Reward\n",
      "RLOO\n",
      "SFT\n",
      "Iterative SFT\n",
      "XPO\n",
      "Model Classes\n",
      "Model Utilities\n",
      "Best of N Sampling\n",
      "Judges\n",
      "Callbacks\n",
      "Data Utilities\n",
      "Reward Functions\n",
      "Script Utilities\n",
      "Others\n",
      "Join the Hugging Face community\n",
      "and get access to the augmented documentation experience\n",
      "Collaborate on models, datasets and Spaces\n",
      "Faster examples with accelerated inference\n",
      "Switch between documentation themes\n",
      "Sign Up\n",
      "to get started\n",
      "TRL - Transformer Reinforcement Learning\n",
      "TRL is a full stack library where we provide a set of tools to train transformer language models with methods like Supervised Fine-Tuning (SFT), Group Relative Policy Optimization (GRPO), Direct Preference Optimization (DPO), Reward Modeling, and more.\n",
      "The library is integrated with 🤗\n",
      "transformers\n",
      ".\n",
      "You can also explore TRL-related models, datasets, and demos in the\n",
      "TRL Hugging Face organization\n",
      ".\n",
      "Learn\n",
      "Learn post-training with TRL and other libraries in 🤗\n",
      "smol course\n",
      ".\n",
      "Contents\n",
      "The documentation is organized into the following sections:\n",
      "Getting Started\n",
      ": installation and quickstart guide.\n",
      "Conceptual Guides\n",
      ": dataset formats, training FAQ, and understanding logs.\n",
      "How-to Guides\n",
      ": reducing memory usage, speeding up training, distributing training, etc.\n",
      "Integrations\n",
      ": DeepSpeed, Liger Kernel, PEFT, etc.\n",
      "Examples\n",
      ": example overview, community tutorials, etc.\n",
      "API\n",
      ": trainers, utils, etc.\n",
      "Blog posts\n",
      "Published on January 28, 2025\n",
      "Open-R1: a fully open reproduction of DeepSeek-R1\n",
      "Published on July 10, 2024\n",
      "Preference Optimization for Vision Language Models with TRL\n",
      "Published on June 12, 2024\n",
      "Putting RL back in RLHF\n",
      "Published on September 29, 2023\n",
      "Finetune Stable Diffusion Models with DDPO via TRL\n",
      "Published on August 8, 2023\n",
      "Fine-tune Llama 2 with DPO\n",
      "Published on April 5, 2023\n",
      "StackLLaMA: A hands-on guide to train LLaMA with RLHF\n",
      "Published on March 9, 2023\n",
      "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU\n",
      "Published on December 9, 2022\n",
      "Illustrating Reinforcement Learning from Human Feedback\n",
      "<\n",
      ">\n",
      "Update\n",
      "on GitHub\n",
      "Installation\n",
      "→\n",
      "TR\n",
      "L -\n",
      "Transformer\n",
      "Reinforcement\n",
      "Learning\n",
      "Learn\n",
      "Contents\n",
      "Blog posts\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/models\n",
      "Webpage Title:\n",
      "Models - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Models filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Tasks\n",
      "Text Generation\n",
      "Any-to-Any\n",
      "Image-Text-to-Text\n",
      "Image-to-Text\n",
      "Image-to-Image\n",
      "Text-to-Image\n",
      "Text-to-Video\n",
      "Text-to-Speech\n",
      "+ 42\n",
      "Parameters\n",
      "Reset Parameters\n",
      "< 1B\n",
      "5B\n",
      "12B\n",
      "32B\n",
      "128B\n",
      "> 500B\n",
      "< 1B\n",
      "> 500B\n",
      "Libraries\n",
      "PyTorch\n",
      "google-tensorflow\n",
      "TensorFlow\n",
      "JAX\n",
      "Transformers\n",
      "Diffusers\n",
      "Safetensors\n",
      "ONNX\n",
      "GGUF\n",
      "Transformers.js\n",
      "MLX\n",
      "Keras\n",
      "+ 39\n",
      "Apps\n",
      "vLLM\n",
      "TGI\n",
      "llama.cpp\n",
      "MLX LM\n",
      "LM Studio\n",
      "Ollama\n",
      "Jan\n",
      "+ 11\n",
      "Inference Providers\n",
      "Together AI\n",
      "Fireworks\n",
      "Novita\n",
      "SambaNova\n",
      "Hyperbolic\n",
      "Cerebras\n",
      "Replicate\n",
      "fal\n",
      "+ 6\n",
      "Apply filters\n",
      "Models\n",
      "Full-text search\n",
      "Add filters\n",
      "Sort: \n",
      "\t\tTrending\n",
      "nanonets/Nanonets-OCR-s\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "about 21 hours ago\n",
      "•\n",
      "7.96k\n",
      "•\n",
      "536\n",
      "mistralai/Magistral-Small-2506\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "13.5k\n",
      "•\n",
      "•\n",
      "460\n",
      "echo840/MonkeyOCR\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "4\n",
      "•\n",
      "351\n",
      "tencent/Hunyuan3D-2.1\n",
      "Image-to-3D\n",
      "•\n",
      "Updated\n",
      "about 22 hours ago\n",
      "•\n",
      "2.75k\n",
      "•\n",
      "272\n",
      "Menlo/Jan-nano\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 3 hours ago\n",
      "•\n",
      "3.29k\n",
      "•\n",
      "168\n",
      "MiniMaxAI/MiniMax-M1-80k\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "3\n",
      "•\n",
      "150\n",
      "vrgamedevgirl84/Wan14BT2VFusioniX\n",
      "Text-to-Video\n",
      "•\n",
      "Updated\n",
      "about 12 hours ago\n",
      "•\n",
      "179\n",
      "openbmb/MiniCPM4-8B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "7.04k\n",
      "•\n",
      "251\n",
      "Qwen/Qwen3-Embedding-0.6B-GGUF\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "18.3k\n",
      "•\n",
      "373\n",
      "deepseek-ai/DeepSeek-R1-0528\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "19 days ago\n",
      "•\n",
      "126k\n",
      "•\n",
      "•\n",
      "2k\n",
      "fishaudio/openaudio-s1-mini\n",
      "Text-to-Speech\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "3.11k\n",
      "•\n",
      "286\n",
      "facebook/vjepa2-vitl-fpc64-256\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.92k\n",
      "•\n",
      "90\n",
      "inclusionAI/Ming-Lite-Omni\n",
      "Any-to-Any\n",
      "•\n",
      "Updated\n",
      "about 19 hours ago\n",
      "•\n",
      "4.22k\n",
      "•\n",
      "103\n",
      "moonshotai/Kimi-Dev-72B\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "86\n",
      "Hcompany/Holo1-7B\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "4.98k\n",
      "•\n",
      "196\n",
      "Qwen/Qwen3-Embedding-0.6B\n",
      "Feature Extraction\n",
      "•\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "162k\n",
      "•\n",
      "246\n",
      "CEIA-UFG/Gemma-3-Gaia-PT-BR-4b-it\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "2.06k\n",
      "•\n",
      "79\n",
      "black-forest-labs/FLUX.1-dev\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "Aug 16, 2024\n",
      "•\n",
      "1.86M\n",
      "•\n",
      "•\n",
      "10.6k\n",
      "google/gemma-3n-E4B-it-litert-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "1.13k\n",
      "ResembleAI/chatterbox\n",
      "Text-to-Speech\n",
      "•\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "•\n",
      "806\n",
      "unsloth/Magistral-Small-2506-GGUF\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "23.2k\n",
      "•\n",
      "74\n",
      "lodestones/Chroma\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "861\n",
      "ByteDance/Dolphin\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "21 days ago\n",
      "•\n",
      "7.12k\n",
      "•\n",
      "327\n",
      "Menlo/Jan-nano-gguf\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 3 hours ago\n",
      "•\n",
      "2.7k\n",
      "•\n",
      "63\n",
      "MiniMaxAI/MiniMax-M1-40k\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "3\n",
      "•\n",
      "60\n",
      "mistralai/Magistral-Small-2506_gguf\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "3.36k\n",
      "•\n",
      "57\n",
      "gdhe17/Self-Forcing\n",
      "Text-to-Video\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "61\n",
      "black-forest-labs/FLUX.1-schnell\n",
      "Text-to-Image\n",
      "•\n",
      "Updated\n",
      "Aug 16, 2024\n",
      "•\n",
      "827k\n",
      "•\n",
      "•\n",
      "3.95k\n",
      "Qwen/Qwen3-Embedding-8B\n",
      "Feature Extraction\n",
      "•\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "34.9k\n",
      "•\n",
      "•\n",
      "141\n",
      "tencent/HunyuanVideo-Avatar\n",
      "Image-to-Video\n",
      "•\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "216\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/datasets\n",
      "Webpage Title:\n",
      "Hugging Face – The AI community building the future.\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Datasets filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Modalities\n",
      "3D\n",
      "Audio\n",
      "Document\n",
      "Geospatial\n",
      "Image\n",
      "Tabular\n",
      "Text\n",
      "Time-series\n",
      "Video\n",
      "Size\n",
      "\t\t\t(rows)\n",
      "Reset Size\n",
      "< 1K\n",
      "> 1T\n",
      "Format\n",
      "json\n",
      "csv\n",
      "parquet\n",
      "imagefolder\n",
      "soundfolder\n",
      "webdataset\n",
      "text\n",
      "arrow\n",
      "Apply filters\n",
      "Datasets\n",
      "425,458\n",
      "Full-text search\n",
      "Add filters\n",
      "Sort: \n",
      "\t\tTrending\n",
      "nvidia/Nemotron-Personas\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "100k\n",
      "•\n",
      "8.82k\n",
      "•\n",
      "116\n",
      "institutional/institutional-books-1.0\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 16 hours ago\n",
      "•\n",
      "983k\n",
      "•\n",
      "2.98k\n",
      "•\n",
      "89\n",
      "fka/awesome-chatgpt-prompts\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 6\n",
      "•\n",
      "203\n",
      "•\n",
      "21.7k\n",
      "•\n",
      "7.94k\n",
      "open-thoughts/OpenThoughts3-1.2M\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "1.2M\n",
      "•\n",
      "15.6k\n",
      "•\n",
      "104\n",
      "miriad/miriad-5.8M\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "5.82M\n",
      "•\n",
      "1.8k\n",
      "•\n",
      "37\n",
      "openbmb/Ultra-FineWeb\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 21 hours ago\n",
      "•\n",
      "1.29B\n",
      "•\n",
      "44.2k\n",
      "•\n",
      "181\n",
      "a-m-team/AM-DeepSeek-R1-0528-Distilled\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "7.65k\n",
      "•\n",
      "69\n",
      "lingshu-medical-mllm/ReasonMed\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "1.11M\n",
      "•\n",
      "156\n",
      "•\n",
      "22\n",
      "open-r1/Mixture-of-Thoughts\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "699k\n",
      "•\n",
      "35.4k\n",
      "•\n",
      "223\n",
      "Dataseeds/DataSeeds.AI-Sample-Dataset-DSD\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "7.77k\n",
      "•\n",
      "1.26k\n",
      "•\n",
      "20\n",
      "PKU-DS-LAB/AcademicBrowse\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "223\n",
      "•\n",
      "124\n",
      "•\n",
      "14\n",
      "AlicanKiraz0/All-CVE-Records-Training-Dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "297k\n",
      "•\n",
      "226\n",
      "•\n",
      "14\n",
      "Anthropic/hh-rlhf\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 26, 2023\n",
      "•\n",
      "169k\n",
      "•\n",
      "10.4k\n",
      "•\n",
      "1.36k\n",
      "PleIAs/common_corpus\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "470M\n",
      "•\n",
      "244k\n",
      "•\n",
      "293\n",
      "IGNF/FLAIR-HUB\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "1.82k\n",
      "•\n",
      "12\n",
      "Josephgflowers/Finance-Instruct-500k\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 1\n",
      "•\n",
      "518k\n",
      "•\n",
      "1.23k\n",
      "•\n",
      "89\n",
      "boltuix/emotions-dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "23 days ago\n",
      "•\n",
      "131k\n",
      "•\n",
      "471\n",
      "•\n",
      "15\n",
      "openai/gsm8k\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 4, 2024\n",
      "•\n",
      "17.6k\n",
      "•\n",
      "490k\n",
      "•\n",
      "764\n",
      "nvidia/Llama-Nemotron-Post-Training-Dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 8\n",
      "•\n",
      "3.91M\n",
      "•\n",
      "10.5k\n",
      "•\n",
      "508\n",
      "common-pile/comma_v0.1_training_dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "784M\n",
      "•\n",
      "9.96k\n",
      "•\n",
      "30\n",
      "CyberNative/Code_Vulnerability_Security_DPO\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 29, 2024\n",
      "•\n",
      "4.66k\n",
      "•\n",
      "819\n",
      "•\n",
      "104\n",
      "cais/hle\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "27 days ago\n",
      "•\n",
      "2.5k\n",
      "•\n",
      "5.9k\n",
      "•\n",
      "355\n",
      "Hcompany/WebClick\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "8 days ago\n",
      "•\n",
      "1.64k\n",
      "•\n",
      "6.64k\n",
      "•\n",
      "53\n",
      "maya-research/IndicVault\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 6\n",
      "•\n",
      "244k\n",
      "•\n",
      "298\n",
      "•\n",
      "43\n",
      "zou-lab/MedCaseReasoning\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "14.5k\n",
      "•\n",
      "795\n",
      "•\n",
      "16\n",
      "yandex/yambda\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "11 days ago\n",
      "•\n",
      "5.31B\n",
      "•\n",
      "47.8k\n",
      "•\n",
      "161\n",
      "nvidia/PhysicalAI-Autonomous-Vehicle-Cosmos-Drive-Dreams\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "3.63k\n",
      "•\n",
      "8\n",
      "Trendyol/All-CVE-Chat-MultiTurn-1999-2025-Dataset\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "297k\n",
      "•\n",
      "173\n",
      "•\n",
      "8\n",
      "HuggingFaceFW/fineweb\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 31\n",
      "•\n",
      "25B\n",
      "•\n",
      "319k\n",
      "•\n",
      "2.2k\n",
      "LeRobot-worldwide-hackathon/submissions\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "about 17 hours ago\n",
      "•\n",
      "2\n",
      "•\n",
      "910\n",
      "•\n",
      "10\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "100\n",
      "Next\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/spaces\n",
      "Webpage Title:\n",
      "Spaces - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Spaces\n",
      "·\n",
      "The AI App Directory\n",
      "New Space\n",
      "Get PRO\n",
      "Learn more\n",
      "Image Generation\n",
      "Video Generation\n",
      "Text Generation\n",
      "Language Translation\n",
      "Speech Synthesis\n",
      "3D Modeling\n",
      "Object Detection\n",
      "Text Analysis\n",
      "Image Editing\n",
      "Code Generation\n",
      "Question Answering\n",
      "Data Visualization\n",
      "Voice Cloning\n",
      "Background Removal\n",
      "Image Upscaling\n",
      "OCR\n",
      "Document Analysis\n",
      "Visual QA\n",
      "Image Captioning\n",
      "Chatbots\n",
      "Sentiment Analysis\n",
      "Text Summarization\n",
      "Music Generation\n",
      "Medical Imaging\n",
      "Financial Analysis\n",
      "Game AI\n",
      "Model Benchmarking\n",
      "Fine Tuning Tools\n",
      "Dataset Creation\n",
      "Pose Estimation\n",
      "Face Recognition\n",
      "Anomaly Detection\n",
      "Recommendation Systems\n",
      "Character Animation\n",
      "Style Transfer\n",
      "Image\n",
      "Spaces of the week\n",
      "16 Jun 2025\n",
      "Filters\n",
      "(0)\n",
      "Sort: \n",
      "\t\tRelevance\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "100\n",
      "Hunyuan3D-2.1\n",
      "👻\n",
      "Image-to-3D Generation\n",
      "tencent\n",
      "about 20 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "55\n",
      "PartPacker\n",
      "🪴\n",
      "Part-level image-to-3D generation.\n",
      "nvidia\n",
      "about 18 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "19\n",
      "Pixel3dmm [Image Mode]\n",
      "📷\n",
      "Versatile Single-Image 3D Face Reconstruction\n",
      "alexnasa\n",
      "3 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "17\n",
      "NAG Wan2-1-fast\n",
      "🏢\n",
      "Demo of Normalized Attention Guidance for 4 steps Wan2.1\n",
      "ChenDY\n",
      "8 days ago\n",
      "Running\n",
      "40\n",
      "MiniMax M1\n",
      "💬\n",
      "MiniMaxAI\n",
      "about 18 hours ago\n",
      "Running\n",
      "13\n",
      "ScouterAI\n",
      "👓\n",
      "The agent using over 9000 vision models from the HF Hub.\n",
      "Agents-MCP-Hackathon\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "19\n",
      "Nanonets OCR\n",
      "👁\n",
      "Demo for Nanonets-OCR\n",
      "MohamedRashad\n",
      "4 days ago\n",
      "Running\n",
      "203\n",
      "Sparc3D\n",
      "🏃\n",
      "Next-Gen High-Resolution 3D Model Generation\n",
      "ilcve21\n",
      "3 days ago\n",
      "All running apps, trending first\n",
      "Running\n",
      "8.14k\n",
      "DeepSite\n",
      "🐳\n",
      "Generate any application with DeepSeek\n",
      "enzostvs\n",
      "about 18 hours ago\n",
      "Running\n",
      "224\n",
      "Sheets\n",
      "🗂\n",
      "Convert ideas into structured datasets\n",
      "aisheets\n",
      "7 days ago\n",
      "Running\n",
      "203\n",
      "Sparc3D\n",
      "🏃\n",
      "Next-Gen High-Resolution 3D Model Generation\n",
      "ilcve21\n",
      "3 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "1.1k\n",
      "Chatterbox TTS\n",
      "🍿\n",
      "Expressive Zeroshot TTS\n",
      "ResembleAI\n",
      "19 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "740\n",
      "Wan2.1 Fast\n",
      "🎥\n",
      "Generate a video animation from an image\n",
      "multimodalart\n",
      "26 days ago\n",
      "Running\n",
      "163\n",
      "Graphify\n",
      "⚡\n",
      "Create multiple diagram types instantly from JSON!\n",
      "Agents-MCP-Hackathon\n",
      "6 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "100\n",
      "Hunyuan3D-2.1\n",
      "👻\n",
      "Image-to-3D Generation\n",
      "tencent\n",
      "about 20 hours ago\n",
      "Running\n",
      "155\n",
      "AI Marketing Content Generator\n",
      "🎨\n",
      "An AI-powered tool made for content creators and marketers\n",
      "Agents-MCP-Hackathon\n",
      "6 days ago\n",
      "Running\n",
      "579\n",
      "Realistic Text To Speech Unlimited\n",
      "🔥\n",
      "Free Text-To-Speech generator with Emotion control (OpenAI)\n",
      "NihalGazi\n",
      "13 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "8.58k\n",
      "FLUX.1 [dev]\n",
      "🖥\n",
      "Generate images from text prompts\n",
      "black-forest-labs\n",
      "Apr 16\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "99\n",
      "Vui\n",
      "🏢\n",
      "NotebookLM conversational speech model\n",
      "fluxions\n",
      "11 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "186\n",
      "MIDJOURNEY\n",
      "🏜\n",
      "MidJour | A RealVisXL_Turbo | IRL HI-Res Images Gen\n",
      "Dagfinn1962\n",
      "Jan 14\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "782\n",
      "LTX Video Fast\n",
      "🎥\n",
      "ultra-fast video model, LTX 0.9.7 13B distilled\n",
      "Lightricks\n",
      "7 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "74\n",
      "CapSpeech TTS\n",
      "🧢\n",
      "Stylized TTS – design voice, accent, and emotion your way\n",
      "OpenSound\n",
      "11 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "55\n",
      "PartPacker\n",
      "🪴\n",
      "Part-level image-to-3D generation.\n",
      "nvidia\n",
      "about 18 hours ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "9.05k\n",
      "Kolors Virtual Try-On\n",
      "👕\n",
      "Upload images to see virtual garment try-on\n",
      "Kwai-Kolors\n",
      "Sep 18, 2024\n",
      "Running\n",
      "186\n",
      "Conversational WebGPU\n",
      "🚀\n",
      "webml-community\n",
      "13 days ago\n",
      "Running\n",
      "118\n",
      "Dots Demo\n",
      "💻\n",
      "Generate responses to text inputs\n",
      "rednote-hilab\n",
      "11 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "5.86k\n",
      "MTEB Leaderboard\n",
      "🥇\n",
      "Embedding Leaderboard\n",
      "mteb\n",
      "Apr 17\n",
      "Running\n",
      "108\n",
      "Organization Activity Heatmap\n",
      "🔥\n",
      "Discover top AI models and labs\n",
      "cfahlgren1\n",
      "4 days ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "10.4k\n",
      "AI Comic Factory\n",
      "👩\n",
      "Create your own AI comic with a single prompt\n",
      "jbilcke-hf\n",
      "Oct 15, 2024\n",
      "Running\n",
      "44\n",
      "LLMGameHub\n",
      "🎮\n",
      "Create an AI-powered game based on your own ideas\n",
      "Agents-MCP-Hackathon\n",
      "6 days ago\n",
      "Running\n",
      "362\n",
      "Direct3D S2 V1.0 Demo\n",
      "💻\n",
      "Generate 3D models using spatial sparse attention\n",
      "wushuang98\n",
      "5 days ago\n",
      "Running\n",
      "56\n",
      "Consilium MCP Server\n",
      "🏢\n",
      "Multi-AI Expert Consensus Platform\n",
      "Agents-MCP-Hackathon\n",
      "7 days ago\n",
      "Previous\n",
      "1\n",
      "2\n",
      "3\n",
      "...\n",
      "100\n",
      "Next\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/pricing\n",
      "Webpage Title:\n",
      "Hugging Face – Pricing\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Users and organizations already use the Hub as a collaboration platform,\n",
      "we’re making it easy to seamlessly and scalably launch ML compute directly from the Hub.\n",
      "HF Hub\n",
      "Collaborate on Machine Learning\n",
      "Host unlimited public models, datasets\n",
      "Create unlimited orgs with no member limits\n",
      "Access the latest ML tools and open source\n",
      "Community support\n",
      "Forever\n",
      "Free\n",
      "PRO\n",
      "PRO Account\n",
      "Unlock advanced HF features\n",
      "ZeroGPU and Dev Mode for Spaces\n",
      "Free credits across all Inference Providers\n",
      "10× Private storage capacity\n",
      "Show your support with a Pro badge\n",
      "Subscribe for\n",
      "$9\n",
      "/month\n",
      "Enterprise Hub\n",
      "Accelerate your AI roadmap\n",
      "SSO and SAML support\n",
      "Select data location with Storage Regions\n",
      "Precise actions reviews with Audit logs\n",
      "Granular access control with Resource groups\n",
      "Centralized token control and approval\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "8× more ZeroGPU quota for all org members\n",
      "Deploy Inference on your own Infra\n",
      "Managed billing with yearly commits\n",
      "Priority support\n",
      "Starting at\n",
      "$20\n",
      "per user per month\n",
      "Spaces Hardware\n",
      "Upgrade your Space compute\n",
      "Free CPUs\n",
      "Build more advanced Spaces\n",
      "7 optimized hardware available\n",
      "From CPU to GPU to Accelerators\n",
      "Starting at\n",
      "$0\n",
      "/hour\n",
      "Inference Endpoints\n",
      "Deploy models on fully managed infrastructure\n",
      "Deploy dedicated Endpoints in seconds\n",
      "Keep your costs low\n",
      "Fully-managed autoscaling\n",
      "Enterprise security\n",
      "Starting at\n",
      "$0.032\n",
      "/hour\n",
      "Need support to accelerate AI in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "→\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $0\n",
      "Spaces are one of the most popular ways to share ML applications and demos with the world.\n",
      "Upgrade your Spaces with our selection of custom on-demand hardware:\n",
      "→\n",
      "Get started with Spaces\n",
      "Name\n",
      "CPU\n",
      "Memory\n",
      "Accelerator\n",
      "VRAM\n",
      "Hourly price\n",
      "CPU Basic\n",
      "2 vCPU\n",
      "16 GB\n",
      "-\n",
      "-\n",
      "FREE\n",
      "CPU Upgrade\n",
      "8 vCPU\n",
      "32 GB\n",
      "-\n",
      "-\n",
      "$0.03\n",
      "Nvidia T4 - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.40\n",
      "Nvidia T4 - medium\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia T4\n",
      "16 GB\n",
      "$0.60\n",
      "1x Nvidia L4\n",
      "8 vCPU\n",
      "30 GB\n",
      "Nvidia L4\n",
      "24 GB\n",
      "$0.80\n",
      "4x Nvidia L4\n",
      "48 vCPU\n",
      "186 GB\n",
      "Nvidia L4\n",
      "96 GB\n",
      "$3.80\n",
      "1x Nvidia L40S\n",
      "8 vCPU\n",
      "62 GB\n",
      "Nvidia L4\n",
      "48 GB\n",
      "$1.80\n",
      "4x Nvidia L40S\n",
      "48 vCPU\n",
      "382 GB\n",
      "Nvidia L4\n",
      "192 GB\n",
      "$8.30\n",
      "8x Nvidia L40S\n",
      "192 vCPU\n",
      "1534 GB\n",
      "Nvidia L4\n",
      "384 GB\n",
      "$23.50\n",
      "Nvidia A10G - small\n",
      "4 vCPU\n",
      "15 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.00\n",
      "Nvidia A10G - large\n",
      "12 vCPU\n",
      "46 GB\n",
      "Nvidia A10G\n",
      "24 GB\n",
      "$1.50\n",
      "2x Nvidia A10G - large\n",
      "24 vCPU\n",
      "92 GB\n",
      "Nvidia A10G\n",
      "48 GB\n",
      "$3.00\n",
      "4x Nvidia A10G - large\n",
      "48 vCPU\n",
      "184 GB\n",
      "Nvidia A10G\n",
      "96 GB\n",
      "$5.00\n",
      "Nvidia A100 - large\n",
      "12 vCPU\n",
      "142 GB\n",
      "Nvidia A100\n",
      "80 GB\n",
      "$2.50\n",
      "Custom\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "on demand\n",
      "Spaces Persistent Storage\n",
      "All Spaces get ephemeral storage for free but you can upgrade and add persistent storage at any time.\n",
      "Name\n",
      "Storage\n",
      "Monthly price\n",
      "Small\n",
      "20 GB\n",
      "$5\n",
      "Medium\n",
      "150 GB\n",
      "$25\n",
      "Large\n",
      "1 TB\n",
      "$100\n",
      "Building something cool as a side project? We also offer community GPU grants.\n",
      "Inference Endpoints\n",
      "Starting at $0.033/hour\n",
      "Inference Endpoints (dedicated) offers a secure production solution to easily deploy any ML model on dedicated\n",
      "\t\t\t\t\tand autoscaling infrastructure, right from the HF Hub.\n",
      "→\n",
      "Learn more\n",
      "CPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "vCPUs\n",
      "Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.03\n",
      "2\n",
      "4GB\n",
      "$0.07\n",
      "4\n",
      "8GB\n",
      "$0.13\n",
      "8\n",
      "16GB\n",
      "$0.27\n",
      "16\n",
      "32GB\n",
      "$0.54\n",
      "azure\n",
      "Intel Xeon\n",
      "1\n",
      "2GB\n",
      "$0.06\n",
      "2\n",
      "4GB\n",
      "$0.12\n",
      "4\n",
      "8GB\n",
      "$0.24\n",
      "8\n",
      "16GB\n",
      "$0.48\n",
      "gcp\n",
      "Intel Sapphire Rapids\n",
      "1\n",
      "2GB\n",
      "$0.05\n",
      "2\n",
      "4GB\n",
      "$0.10\n",
      "4\n",
      "8GB\n",
      "$0.20\n",
      "8\n",
      "16GB\n",
      "$0.40\n",
      "Accelerator\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "Topology\n",
      "Accelerator Memory\n",
      "Hourly rate\n",
      "aws\n",
      "Inf2\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tNeuron\n",
      "x1\n",
      "14.5GB\n",
      "$0.75\n",
      "x12\n",
      "760GB\n",
      "$12.00\n",
      "gcp\n",
      "TPU\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tv5e\n",
      "1x1\n",
      "16GB\n",
      "$1.20\n",
      "2x2\n",
      "64GB\n",
      "$4.75\n",
      "2x4\n",
      "128GB\n",
      "$9.50\n",
      "GPU\n",
      "instances\n",
      "Provider\n",
      "Architecture\n",
      "GPUs\n",
      "GPU Memory\n",
      "Hourly rate\n",
      "aws\n",
      "NVIDIA T4\n",
      "1\n",
      "14GB\n",
      "$0.50\n",
      "4\n",
      "56GB\n",
      "$3.00\n",
      "aws\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.80\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "aws\n",
      "NVIDIA L40S\n",
      "1\n",
      "48GB\n",
      "$1.80\n",
      "4\n",
      "192GB\n",
      "$8.30\n",
      "8\n",
      "384GB\n",
      "$23.50\n",
      "aws\n",
      "NVIDIA A10G\n",
      "1\n",
      "24GB\n",
      "$1.00\n",
      "4\n",
      "96GB\n",
      "$5.00\n",
      "aws\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$2.50\n",
      "2\n",
      "160GB\n",
      "$5.00\n",
      "4\n",
      "320GB\n",
      "$10.00\n",
      "8\n",
      "640GB\n",
      "$20.00\n",
      "aws\n",
      "NVIDIA H200\n",
      "1\n",
      "141GB\n",
      "$5.00\n",
      "2\n",
      "282GB\n",
      "$10.00\n",
      "4\n",
      "564GB\n",
      "$20.00\n",
      "8\n",
      "1128GB\n",
      "$40.00\n",
      "gcp\n",
      "NVIDIA T4\n",
      "1\n",
      "16GB\n",
      "$0.50\n",
      "gcp\n",
      "NVIDIA L4\n",
      "1\n",
      "24GB\n",
      "$0.70\n",
      "4\n",
      "96GB\n",
      "$3.80\n",
      "gcp\n",
      "NVIDIA A100\n",
      "1\n",
      "80GB\n",
      "$3.60\n",
      "2\n",
      "160GB\n",
      "$7.20\n",
      "4\n",
      "320GB\n",
      "$14.40\n",
      "8\n",
      "640GB\n",
      "$28.80\n",
      "gcp\n",
      "NVIDIA H100\n",
      "1\n",
      "80GB\n",
      "$10.00\n",
      "2\n",
      "160GB\n",
      "$20.00\n",
      "4\n",
      "320GB\n",
      "$40.00\n",
      "8\n",
      "640GB\n",
      "$80.00\n",
      "PRO Account\n",
      "PRO\n",
      "A monthly subscription to access powerful features.\n",
      "→\n",
      "Get PRO\n",
      "($9/month)\n",
      "ZeroGPU\n",
      ": Get 8× usage quota and highest GPU queue priority\n",
      "Spaces Hosting\n",
      ": Create ZeroGPU Spaces with H200 hardware\n",
      "Spaces Dev Mode\n",
      ": Fast iterations via SSH/VS Code for Spaces\n",
      "Inference Providers\n",
      ": Get $2 included credits across all Inference Providers\n",
      "Dataset Viewer\n",
      ": Activate it on private datasets\n",
      "Blog Articles\n",
      ": Publish articles to the Hugging Face blog\n",
      "Social Posts\n",
      ": Share short updates with the community\n",
      "Features Preview\n",
      ": Get early access to upcoming\n",
      "\t\t\t\t\t\t\t\t\t\tfeatures\n",
      "PRO\n",
      "Badge\n",
      ":\n",
      "\t\t\t\t\t\t\t\t\t\tShow your support on your profile\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/enterprise\n",
      "Webpage Title:\n",
      "Enterprise Hub - Hugging Face\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Enterprise Hub\n",
      "Enterprise-ready version of the world’s leading AI platform\n",
      "Subscribe to\n",
      "Enterprise Hub\n",
      "from $20/user/month with your Hub organization\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Enterprise Hub\n",
      "or\n",
      "Talk to sales\n",
      "NVIDIA\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "412 models\n",
      "•\n",
      "29.2k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "2.17k models\n",
      "•\n",
      "6.46k followers\n",
      "Snowflake\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "23 models\n",
      "•\n",
      "541 followers\n",
      "Arm\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "217 followers\n",
      "Qwen\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "321 models\n",
      "•\n",
      "35.1k followers\n",
      "Xsolla\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "139 followers\n",
      "Nutanix\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "261 models\n",
      "•\n",
      "110 followers\n",
      "Jusbrasil\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "98 followers\n",
      "creditkarma\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "70 followers\n",
      "Johnson & Johnson\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "71 followers\n",
      "HyperCLOVA X\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "3 models\n",
      "•\n",
      "353 followers\n",
      "LinkedIn\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "62 followers\n",
      "Widn AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "48 followers\n",
      "Stability AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "108 models\n",
      "•\n",
      "25.2k followers\n",
      "Meta Llama\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "70 models\n",
      "•\n",
      "48.4k followers\n",
      "Nerdy Face\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "302 followers\n",
      "Orange\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "234 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "21 models\n",
      "•\n",
      "296 followers\n",
      "ServiceNow\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "511 followers\n",
      "ServiceNow-AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "3 models\n",
      "•\n",
      "287 followers\n",
      "Fidelity Investments\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "151 followers\n",
      "TNG Technology Consulting GmbH\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "4 models\n",
      "•\n",
      "155 followers\n",
      "Technology Innovation Institute\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "101 models\n",
      "•\n",
      "1.44k followers\n",
      "Chegg Inc\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "87 followers\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "164 followers\n",
      "Liquid AI\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "205 followers\n",
      "BCG X\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "40 followers\n",
      "Adyen\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "68 followers\n",
      "Shopify\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "477 followers\n",
      "AMD\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "145 models\n",
      "•\n",
      "1.6k followers\n",
      "JetBrains\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "560 followers\n",
      "Together\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "33 models\n",
      "•\n",
      "624 followers\n",
      "LiveRAG by AIIR\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "130 followers\n",
      "Toyota Research Institute\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "10 models\n",
      "•\n",
      "122 followers\n",
      "Deutsche Telekom AG\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "152 followers\n",
      "IBM Granite\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "124 models\n",
      "•\n",
      "1.89k followers\n",
      "H2O.ai\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "71 models\n",
      "•\n",
      "428 followers\n",
      "HiddenLayer\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "1 model\n",
      "•\n",
      "74 followers\n",
      "MiniMax\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "7 models\n",
      "•\n",
      "814 followers\n",
      "Lightricks\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "13 models\n",
      "•\n",
      "1.06k followers\n",
      "Novo Nordisk R&ED\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "37 followers\n",
      "Twelve Labs\n",
      "Enterprise\n",
      "company\n",
      "•\n",
      "47 followers\n",
      "Compliance & Certifications\n",
      "GDPR Compliant\n",
      "SOC 2 Type 2\n",
      "System theme\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Changelog\n",
      "Inference Endpoints\n",
      "HuggingChat\n",
      "Company\n",
      "About\n",
      "Brand assets\n",
      "Terms of service\n",
      "Privacy\n",
      "Jobs\n",
      "Press\n",
      "Resources\n",
      "Learn\n",
      "Documentation\n",
      "Blog\n",
      "Forum\n",
      "Service Status\n",
      "Social\n",
      "GitHub\n",
      "Twitter\n",
      "LinkedIn\n",
      "Discord\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/allenai\n",
      "Webpage Title:\n",
      "allenai (Ai2)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Ai2\n",
      "Enterprise\n",
      "non-profit\n",
      "Verified\n",
      "https://allenai.org/\n",
      "allen_ai\n",
      "allenai\n",
      "Activity Feed\n",
      "Follow\n",
      "3,441\n",
      "AI & ML interests\n",
      "Building breatkthrough AI to solve the world's biggest problems.\n",
      "Recent Activity\n",
      "amanrangapur\n",
      "new\n",
      "activity\n",
      "4 days ago\n",
      "allenai/olmOCR-7B-0225-preview-GGUF:\n",
      "How to Use olmOCR GGUF Model with Ollama?\n",
      "drschwenk\n",
      "updated\n",
      "a dataset\n",
      "5 days ago\n",
      "allenai/ruler_data\n",
      "abhaybd\n",
      "authored\n",
      "a paper\n",
      "12 days ago\n",
      "CCIL: Continuity-based Data Augmentation for Corrective Imitation\n",
      "  Learning\n",
      "View all activity\n",
      "Articles\n",
      "Introducing the Open Chain of Thought Leaderboard\n",
      "Apr 23, 2024\n",
      "•\n",
      "34\n",
      "Team members\n",
      "188\n",
      "+154\n",
      "+141\n",
      "+120\n",
      "+110\n",
      "+90\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Collections\n",
      "21\n",
      "Reward Bench 2\n",
      "Datasets, spaces, and models for Reward Bench 2 benchmark and paper!\n",
      "allenai/reward-bench-2\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "1.87k\n",
      "•\n",
      "1.23k\n",
      "•\n",
      "18\n",
      "Running\n",
      "378\n",
      "378\n",
      "Reward Bench Leaderboard\n",
      "📐\n",
      "Display and filter reward model evaluation data\n",
      "allenai/reward-bench-2-results\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "273\n",
      "•\n",
      "1\n",
      "allenai/Llama-3.1-70B-Instruct-RM-RB2\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "92\n",
      "OLMo 2\n",
      "Artifacts for the OLMo 2 release.\n",
      "allenai/OLMo-2-0425-1B-Instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 30\n",
      "•\n",
      "7.02k\n",
      "•\n",
      "39\n",
      "allenai/OLMo-2-0425-1B-Instruct-GGUF\n",
      "Updated\n",
      "May 1\n",
      "•\n",
      "573\n",
      "•\n",
      "8\n",
      "allenai/OLMo-2-0425-1B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "19 days ago\n",
      "•\n",
      "37.8k\n",
      "•\n",
      "48\n",
      "allenai/OLMo-2-0325-32B-Instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 14\n",
      "•\n",
      "5.62k\n",
      "•\n",
      "135\n",
      "Expand 21 collections\n",
      "spaces\n",
      "10\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "378\n",
      "Reward Bench Leaderboard\n",
      "📐\n",
      "Display and filter reward model evaluation data\n",
      "allenai\n",
      "14 days ago\n",
      "pinned\n",
      "Running\n",
      "87\n",
      "Zebra Logic Bench\n",
      "🦓\n",
      "Render a leaderboard for model evaluation\n",
      "allenai\n",
      "Apr 2\n",
      "pinned\n",
      "Running\n",
      "3\n",
      "SUPER Leaderboard\n",
      "🤖\n",
      "allenai\n",
      "Feb 10\n",
      "pinned\n",
      "Runtime error\n",
      "2\n",
      "HREF Leaderboard\n",
      "📐\n",
      "allenai\n",
      "Dec 23, 2024\n",
      "pinned\n",
      "Running\n",
      "51\n",
      "ZeroEval Leaderboard\n",
      "📊\n",
      "Embed and use ZeroEval for evaluation tasks\n",
      "allenai\n",
      "Nov 22, 2024\n",
      "pinned\n",
      "Runtime error\n",
      "22\n",
      "BaseChat by URIAL (Chat with base, untuned LLMs)\n",
      "💬\n",
      "Chat with advanced language models\n",
      "allenai\n",
      "Aug 6, 2024\n",
      "Expand\n",
      "\t\t\t\t\t\t\t10\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "765\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "allenai/Llama-3.1-Tulu-3-405B-DPO\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "42\n",
      "•\n",
      "6\n",
      "allenai/Llama-3.1-Tulu-3-70B-DPO\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.44k\n",
      "•\n",
      "9\n",
      "allenai/Llama-3.1-Tulu-3-8B-DPO\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "4.65k\n",
      "•\n",
      "24\n",
      "allenai/OLMo-2-1124-7B-RM\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "1.12k\n",
      "•\n",
      "3\n",
      "allenai/GraspMolmo\n",
      "Robotics\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "351\n",
      "•\n",
      "4\n",
      "allenai/ACE2-ERA5\n",
      "Updated\n",
      "10 days ago\n",
      "•\n",
      "4\n",
      "allenai/Llama-3.1-Tulu-3-70B-SFT-RM-RB2\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "52\n",
      "allenai/Llama-3.1-8B-Base-RM-RB2\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "100\n",
      "allenai/Llama-3.1-Tulu-3-8B-SFT-RM-RB2\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "53\n",
      "allenai/Llama-3.1-Tulu-3-8B-DPO-RM-RB2\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "149\n",
      "Expand\n",
      "\t\t\t\t\t\t\t765\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "236\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "allenai/ruler_data\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "216\n",
      "allenai/reward-bench-2-results\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "273\n",
      "•\n",
      "1\n",
      "allenai/PRISM\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "412k\n",
      "•\n",
      "361\n",
      "•\n",
      "2\n",
      "allenai/SimpleToM-rich\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "4.59k\n",
      "•\n",
      "255\n",
      "•\n",
      "1\n",
      "allenai/reward-bench-2\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "1.87k\n",
      "•\n",
      "1.23k\n",
      "•\n",
      "18\n",
      "allenai/IF_multi_constraints_upto5\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "95.4k\n",
      "•\n",
      "301\n",
      "allenai/sciriff-yesno\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "2.24k\n",
      "•\n",
      "382\n",
      "allenai/blog-images\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "15 days ago\n",
      "•\n",
      "2\n",
      "•\n",
      "27.2k\n",
      "allenai/WildChat-4M-Full\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "57\n",
      "allenai/WildChat-4M\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "58\n",
      "•\n",
      "1\n",
      "Expand\n",
      "\t\t\t\t\t\t\t236\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/facebook\n",
      "Webpage Title:\n",
      "facebook (AI at Meta)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://ai.facebook.com/\n",
      "facebookresearch\n",
      "Activity Feed\n",
      "Follow\n",
      "6,458\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "mduppes\n",
      "updated\n",
      "a Space\n",
      "about 7 hours ago\n",
      "facebook/omnisealbench\n",
      "mduppes\n",
      "new\n",
      "activity\n",
      "about 18 hours ago\n",
      "facebook/bouquet:\n",
      "Add the link to the new tool and dataset\n",
      "cointegrated\n",
      "new\n",
      "activity\n",
      "about 21 hours ago\n",
      "facebook/bouquet:\n",
      "Add the link to the new tool and dataset\n",
      "View all activity\n",
      "Articles\n",
      "Faster Text Generation with Self-Speculative Decoding\n",
      "Nov 20, 2024\n",
      "•\n",
      "58\n",
      "Team members\n",
      "309\n",
      "+275\n",
      "+262\n",
      "+241\n",
      "+231\n",
      "+211\n",
      "Collections\n",
      "30\n",
      "V-JEPA 2\n",
      "A frontier video understanding model developed by FAIR, Meta, which extends the pretraining objectives of https://ai.meta.com/blog/v-jepa-yann\n",
      "facebook/vjepa2-vitl-fpc64-256\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.92k\n",
      "•\n",
      "90\n",
      "facebook/vjepa2-vith-fpc64-256\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "322\n",
      "•\n",
      "11\n",
      "facebook/vjepa2-vitg-fpc64-256\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "6.29k\n",
      "•\n",
      "6\n",
      "facebook/vjepa2-vitg-fpc64-384\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.55k\n",
      "•\n",
      "23\n",
      "Web-SSL\n",
      "facebook/webssl-dino300m-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "Apr 24\n",
      "•\n",
      "3.45k\n",
      "•\n",
      "9\n",
      "facebook/webssl-dino1b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "Apr 24\n",
      "•\n",
      "1.9k\n",
      "•\n",
      "1\n",
      "facebook/webssl-dino2b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "Apr 24\n",
      "•\n",
      "78\n",
      "facebook/webssl-dino3b-full2b-224\n",
      "Image Feature Extraction\n",
      "•\n",
      "Updated\n",
      "Apr 24\n",
      "•\n",
      "102\n",
      "Expand 30 collections\n",
      "spaces\n",
      "39\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "101\n",
      "MelodyFlow\n",
      "🎵\n",
      "Generate music from text and melody\n",
      "facebook\n",
      "Jan 4\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "268\n",
      "CoTracker\n",
      "🎨\n",
      "Track points in a video\n",
      "facebook\n",
      "Oct 17, 2024\n",
      "pinned\n",
      "Running\n",
      "on\n",
      "A10G\n",
      "4.99k\n",
      "MusicGen\n",
      "🎵\n",
      "Generate music from text descriptions\n",
      "facebook\n",
      "Dec 20, 2023\n",
      "Running\n",
      "Omniseal Leaderboard\n",
      "🦀\n",
      "Leaderboard for watermarking models\n",
      "facebook\n",
      "about 7 hours ago\n",
      "Running\n",
      "11\n",
      "Bouquet\n",
      "🔥\n",
      "Universal Quality Evaluation in Translation\n",
      "facebook\n",
      "about 18 hours ago\n",
      "Runtime error\n",
      "11\n",
      "Leaderboard: Physical Reasoning from Video\n",
      "🏃\n",
      "Submit model results to leaderboard\n",
      "facebook\n",
      "6 days ago\n",
      "Expand\n",
      "\t\t\t\t\t\t\t39\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "2,166\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "facebook/vjepa2-vitg-fpc64-384-ssv2\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "22\n",
      "•\n",
      "1\n",
      "facebook/vjepa2-vitg-fpc32-384-diving48\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "5\n",
      "•\n",
      "1\n",
      "facebook/vjepa2-vitl-fpc16-256-ssv2\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "32\n",
      "•\n",
      "1\n",
      "facebook/vjepa2-vitl-fpc32-256-diving48\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "16\n",
      "facebook/OC25\n",
      "Updated\n",
      "4 days ago\n",
      "facebook/ODAC25\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "1\n",
      "facebook/OMC25\n",
      "Updated\n",
      "4 days ago\n",
      "facebook/UMA\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "21\n",
      "•\n",
      "87\n",
      "facebook/vjepa2-vitg-fpc64-384\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "1.55k\n",
      "•\n",
      "23\n",
      "facebook/vjepa2-vitg-fpc64-256\n",
      "Video Classification\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "6.29k\n",
      "•\n",
      "6\n",
      "Expand\n",
      "\t\t\t\t\t\t\t2,166\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "69\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "facebook/bouquet\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "25.9k\n",
      "•\n",
      "10\n",
      "facebook/IntPhys2\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "1.07k\n",
      "•\n",
      "476\n",
      "•\n",
      "6\n",
      "facebook/minimal_video_pairs\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "73.2k\n",
      "•\n",
      "227\n",
      "•\n",
      "4\n",
      "facebook/PLM-VideoBench\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "26 days ago\n",
      "•\n",
      "44k\n",
      "•\n",
      "945\n",
      "•\n",
      "9\n",
      "facebook/PLM-Video-Human\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "26 days ago\n",
      "•\n",
      "2.8M\n",
      "•\n",
      "1.14k\n",
      "•\n",
      "23\n",
      "facebook/TAPAS\n",
      "Updated\n",
      "May 15\n",
      "•\n",
      "151\n",
      "•\n",
      "2\n",
      "facebook/multiloko\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 14\n",
      "•\n",
      "67.3k\n",
      "•\n",
      "193\n",
      "•\n",
      "1\n",
      "facebook/Wildchat-RIP-Filtered-by-8b-Llama\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 13\n",
      "•\n",
      "24.3k\n",
      "•\n",
      "48\n",
      "•\n",
      "2\n",
      "facebook/llamafirewall-alignmentcheck-evals\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 29\n",
      "•\n",
      "3.46k\n",
      "•\n",
      "135\n",
      "facebook/PLM-Image-Auto\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 21\n",
      "•\n",
      "30.3M\n",
      "•\n",
      "689\n",
      "•\n",
      "14\n",
      "Expand\n",
      "\t\t\t\t\t\t\t69\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/amazon\n",
      "Webpage Title:\n",
      "amazon (Amazon)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Amazon\n",
      "company\n",
      "https://aws.amazon.com/\n",
      "aws\n",
      "Activity Feed\n",
      "Request to join this org\n",
      "Follow\n",
      "3,235\n",
      "AI & ML interests\n",
      "Scalable Artificial Intelligence\n",
      "Recent Activity\n",
      "cperiz\n",
      "authored\n",
      "a paper\n",
      "15 days ago\n",
      "K-Edit: Language Model Editing with Contextual Knowledge Awareness\n",
      "cperiz\n",
      "authored\n",
      "a paper\n",
      "15 days ago\n",
      "Towards Safety Reasoning in LLMs: AI-agentic Deliberation for\n",
      "  Policy-embedded CoT Data Creation\n",
      "hyandell\n",
      "updated\n",
      "a model\n",
      "19 days ago\n",
      "amazon/bort\n",
      "View all activity\n",
      "Team members\n",
      "19\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Innovating with machine learning on AWS\n",
      "On AWS, you can access performant infrastructure, deployment resources, data governance solutions, and deep learning containers (DLCs) with optimized open source frameworks, so that you can focus on your machine learning tasks.\n",
      "Build and Scale AI/ML on AWS\n",
      "AWS offers a comprehensive suite of AI/ML tools and services that cater to every stage of the machine learning lifecycle. From model development and training to deployment and inference, AWS provides cutting-edge solutions such as Amazon SageMaker AI, a fully-managed service for end-to-end development and deployment of models, Amazon Bedrock for building and scaling generative AI applications with foundation models, custom AI accelerator chips such as AWS Trainium for training and AWS Inferentia for inference, and pre-configured environments to streamline your ML workflows. Additionally, you can explore the Registry of Open Data to discover, access, and utilize diverse datasets for your AI/ML projects. Whether you're working on large language models, generative AI, computer vision, time-series forecasting, or natural language processing, scaling your projects on AWS is easy.\n",
      "Learn more about these services and others:\n",
      "Amazon SageMaker AI\n",
      "Amazon Bedrock\n",
      "AWS AI Chips\n",
      "AWS GPUs for Machine Learning\n",
      "AWS Deep Learning AMIs\n",
      "AWS Deep Learning Containers (DLCs)\n",
      "Artificial Intelligence on AWS\n",
      "Registry of Open Data\n",
      "AWS & Hugging Face Collaboration\n",
      "AWS and Hugging Face are working together to simplify and accelerate the adoption of advanced machine learning models. This\n",
      "collaboration\n",
      "offers streamlined training using Hugging Face Deep Learning Containers with SageMaker AI distributed training libraries, simplifying workflows with the SageMaker AI Python SDK for efficient model training. Deployment is made effortless through the Hugging Face Inference toolkit and DLCs, allowing users to deploy trained models on the Hugging Face Hub. Amazon SageMaker AI facilitates the creation of scalable endpoints with built-in monitoring and enterprise-level security. This joint effort empowers teams to move quickly from experimentation to production, leveraging cutting-edge models and scalable infrastructure to drive innovation in machine learning projects.\n",
      "Learn about\n",
      "Hugging Face on AWS\n",
      "Learn about\n",
      "Hugging Face on Amazon SageMaker AI\n",
      "Reference documentation for\n",
      "using Hugging Face with Amazon SageMaker AI\n",
      "Community Forum\n",
      "on Hugging Face\n",
      "Connect, Learn, and Grow with AWS\n",
      "Stay connected with the latest AWS AI/ML and open source developments:\n",
      "AWS Open Source\n",
      "AWS on GitHub\n",
      "AWS on LinkedIn\n",
      "Open Source At AWS\n",
      "Amazon Science\n",
      "Amazon Science on GitHub\n",
      "Amazon Science on LinkedIn\n",
      "Code and Datasets from Amazon Researchers\n",
      "AWS Community\n",
      "AWS Machine Learning Blog\n",
      "AWS Community Posts about Hugging Face\n",
      "AWS Community Posts about AI/ML\n",
      "AWS Developers\n",
      "Generative AI on AWS\n",
      "Data and Machine Learning on AWS\n",
      "ML Specialist Training & Resources\n",
      "Check out these other Amazon-run Hugging Face organizations\n",
      "AutoGluon\n",
      "AWS Inferentia and Trainium\n",
      "Amazon Science\n",
      "Let's innovate together! 🎉🚀\n",
      "LLM experimentation at scale using Amazon SageMaker Pipelines and MLflow\n",
      "Build a Hugging Face text classification model in Amazon SageMaker JumpStart\n",
      "Inference AudioCraft MusicGen models using Amazon SageMaker\n",
      "Collections\n",
      "2\n",
      "Chronos-Bolt⚡️ Models\n",
      "Chronos-Bolt pretrained models for time series forecasting.\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "1.89M\n",
      "•\n",
      "22\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "118k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "592k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "4.6M\n",
      "•\n",
      "50\n",
      "Chronos Models & Datasets\n",
      "Collection of artifacts related to Chronos pretrained models for time series forecasting.\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "1.89M\n",
      "•\n",
      "22\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "118k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "592k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "4.6M\n",
      "•\n",
      "50\n",
      "models\n",
      "20\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "amazon/bort\n",
      "Fill-Mask\n",
      "•\n",
      "Updated\n",
      "19 days ago\n",
      "•\n",
      "323\n",
      "•\n",
      "16\n",
      "amazon/chronos-bolt-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "1.89M\n",
      "•\n",
      "22\n",
      "amazon/chronos-bolt-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "118k\n",
      "•\n",
      "5\n",
      "amazon/chronos-bolt-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "592k\n",
      "•\n",
      "10\n",
      "amazon/chronos-bolt-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "4.6M\n",
      "•\n",
      "50\n",
      "amazon/chronos-t5-large\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "200k\n",
      "•\n",
      "148\n",
      "amazon/chronos-t5-base\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "388k\n",
      "•\n",
      "32\n",
      "amazon/chronos-t5-small\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "72.3M\n",
      "•\n",
      "92\n",
      "amazon/chronos-t5-mini\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "76.3k\n",
      "•\n",
      "16\n",
      "amazon/chronos-t5-tiny\n",
      "Time Series Forecasting\n",
      "•\n",
      "Updated\n",
      "Feb 17\n",
      "•\n",
      "874k\n",
      "•\n",
      "109\n",
      "Expand\n",
      "\t\t\t\t\t\t\t20\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "2\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "amazon/CodePrefBench\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Nov 25, 2024\n",
      "•\n",
      "50\n",
      "•\n",
      "1\n",
      "amazon/AmazonQAC\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Nov 19, 2024\n",
      "•\n",
      "396M\n",
      "•\n",
      "178\n",
      "•\n",
      "14\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/google\n",
      "Webpage Title:\n",
      "google (Google)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Google\n",
      "company\n",
      "Verified\n",
      "Activity Feed\n",
      "Follow\n",
      "16,757\n",
      "AI & ML interests\n",
      "Google ❤️ Open Source AI\n",
      "Recent Activity\n",
      "BalakrishnaCh\n",
      "new\n",
      "activity\n",
      "about 22 hours ago\n",
      "google/shieldgemma-2-4b-it:\n",
      "Add context via a prompt\n",
      "lkv\n",
      "new\n",
      "activity\n",
      "about 23 hours ago\n",
      "google/gemma-3-27b-it:\n",
      "Specification\n",
      "BalakrishnaCh\n",
      "new\n",
      "activity\n",
      "1 day ago\n",
      "google/gemma-3-4b-it:\n",
      "Missing values in 4B, 12B config.json\n",
      "View all activity\n",
      "Articles\n",
      "PaliGemma 2 Mix - New Instruction Vision Language Models by Google\n",
      "Feb 19\n",
      "•\n",
      "70\n",
      "Welcome PaliGemma 2 – New vision language models by Google\n",
      "Dec 5, 2024\n",
      "•\n",
      "155\n",
      "PaliGemma – Google's Cutting-Edge Open Vision Language Model\n",
      "May 14, 2024\n",
      "•\n",
      "253\n",
      "Team members\n",
      "2526\n",
      "+2492\n",
      "+2479\n",
      "+2458\n",
      "+2448\n",
      "+2428\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Welcome to the official Google organization on Hugging Face!\n",
      "Google collaborates with Hugging Face\n",
      "across open science, open source, cloud, and hardware to\n",
      "enable companies to innovate with AI\n",
      "on Google Cloud AI services and infrastructure with the Hugging Face ecosystem\n",
      ".\n",
      "Featured Models and Tools\n",
      "Gemma Family of Open Multimodal Models\n",
      "Gemma\n",
      "is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models\n",
      "PaliGemma\n",
      "is a versatile and lightweight vision-language model (VLM)\n",
      "CodeGemma\n",
      "is a collection of lightweight open code models built on top of Gemma\n",
      "RecurrentGemma\n",
      "is a family of open language models built on a novel recurrent architecture developed at Google\n",
      "ShieldGemma\n",
      "is a series of safety content moderation models built upon Gemma 2 that target four harm categories\n",
      "Health AI Developer Foundations\n",
      "MedGemma\n",
      "collection of open models for medical image and text comprehension to accelerate building healthcare-based AI applications\n",
      "TxGemma\n",
      "collection of open models to accelerate the development of therapeutics\n",
      "CXR Foundation\n",
      "embedding model for efficiently building AI for chest X-ray applications\n",
      "Path Foundation\n",
      "embedding model for efficiently building AI for histopathology applications\n",
      "Derm Foundation\n",
      "embedding model for efficiently building AI for skin imaging applications\n",
      "HeAR\n",
      "(\n",
      "TensorFlow\n",
      ",\n",
      "PyTorch\n",
      ") embedding model for efficiently building AI related to audio originating from the respiratory system\n",
      "BERT\n",
      ",\n",
      "T5\n",
      ", and\n",
      "TimesFM\n",
      "Model Families\n",
      "Author ML models with\n",
      "MaxText\n",
      ",\n",
      "JAX\n",
      ",\n",
      "Keras\n",
      ",\n",
      "Tensorflow\n",
      ", and\n",
      "PyTorch/XLA\n",
      "SynthID\n",
      "is a Google DeepMind technology that watermarks and identifies AI-generated content (\n",
      "🤗 Space\n",
      ")\n",
      "Open Research and Community Resources\n",
      "Google Blogs\n",
      ":\n",
      "https://blog.google/\n",
      "https://cloud.google.com/blog/\n",
      "https://deepmind.google/discover/blog/\n",
      "https://developers.google.com/learn?category=aiandmachinelearning\n",
      "https://research.google/blog/\n",
      "Notable GitHub Repositories\n",
      ":\n",
      "https://github.com/google/jax\n",
      "is a Python library for high-performance numerical computing and machine learning\n",
      "https://github.com/huggingface/Google-Cloud-Containers\n",
      "facilitate the training and deployment of Hugging Face models on Google Cloud\n",
      "https://github.com/pytorch/xla\n",
      "enables PyTorch on XLA Devices (e.g. Google TPU)\n",
      "https://github.com/huggingface/optimum-tpu\n",
      "brings the power of TPUs to your training and inference stack\n",
      "https://github.com/openxla/xla\n",
      "is a machine learning compiler for GPUs, CPUs, and ML accelerators\n",
      "https://github.com/google/JetStream\n",
      "(and\n",
      "https://github.com/google/jetstream-pytorch\n",
      ") is a throughput and memory optimized engine for large language model (LLM) inference on XLA devices\n",
      "https://github.com/google/flax\n",
      "is a neural network library for JAX that is designed for flexibility\n",
      "https://github.com/kubernetes-sigs/lws\n",
      "facilitates Kubernetes deployment patterns for AI/ML inference workloads, especially multi-host inference workloads\n",
      "https://gke-ai-labs.dev/\n",
      "is a collection of AI examples, best-practices, and prebuilt solutions\n",
      "Google Research Papers\n",
      ":\n",
      "https://research.google/\n",
      "On-device ML using\n",
      "Google AI Edge\n",
      "Customize and run common ML Tasks with low-code\n",
      "MediaPipe Solutions\n",
      "Run\n",
      "pretrained\n",
      "or custom models on-device with\n",
      "Lite RT (previously known as TensorFlow Lite)\n",
      "Convert\n",
      "TensorFlow\n",
      "and\n",
      "JAX\n",
      "models to LiteRT\n",
      "Convert PyTorch models to LiteRT and author high performance on-device LLMs with\n",
      "AI Edge Torch\n",
      "Visualize and debug models with\n",
      "Model Explorer\n",
      "(\n",
      "🤗 Space\n",
      ")\n",
      "Partnership Highlights and Resources\n",
      "Select Google Cloud CPU, GPU, or TPU options when setting up your\n",
      "Hugging Face\n",
      "Inference Endpoints\n",
      "and Spaces\n",
      "Train and Deploy Hugging Face models\n",
      "on Google Kubernetes Engine (GKE) and Vertex AI\n",
      "directly from Hugging Face model landing pages or from Google Cloud Model Garden\n",
      "Integrate\n",
      "Colab\n",
      "notebooks with Hugging Face Hub\n",
      "via the\n",
      "HF_TOKEN secret manager integration\n",
      "and transformers/huggingface_hub pre-installs\n",
      "Leverage\n",
      "Hugging Face Deep Learning Containers (DLCs)\n",
      "for easy training and deployment of Hugging Face models on Google Cloud infrastructure\n",
      "Run optimized, zero-configuration inference microservices with\n",
      "Hugging Face Generative AI Services (HUGS) via the Google Cloud Marketplace\n",
      "Read about our principles for responsible AI at\n",
      "https://ai.google/responsibility/principles\n",
      "Collections\n",
      "38\n",
      "Gemma 3n Preview\n",
      "google/gemma-3n-E2B-it-litert-lm-preview\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "32\n",
      "google/gemma-3n-E4B-it-litert-lm-preview\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "10\n",
      "google/gemma-3n-E4B-it-litert-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "1.13k\n",
      "google/gemma-3n-E2B-it-litert-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "27 days ago\n",
      "•\n",
      "382\n",
      "HAI-DEF Concept Apps\n",
      "Collection of concept apps built around HAI-DEF open models to inspire the community. Go build with #HAI-DEF! Learn more at http://goo.gle/hai-def\n",
      "Running\n",
      "17\n",
      "17\n",
      "Path Foundation Demo\n",
      "🔬\n",
      "Access pathology images for medical reference\n",
      "Running\n",
      "14\n",
      "14\n",
      "CXR Foundation Demo\n",
      "🩻\n",
      "Demo usage of the CXR Foundation model embeddings\n",
      "Running\n",
      "137\n",
      "137\n",
      "MedGemma - Radiology Explainer Demo\n",
      "🩺\n",
      "Radiology Image & Report Explainer Demo. Built with MedGemma\n",
      "Expand 38 collections\n",
      "spaces\n",
      "9\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Running\n",
      "137\n",
      "MedGemma - Radiology Explainer Demo\n",
      "🩺\n",
      "Radiology Image & Report Explainer Demo. Built with MedGemma\n",
      "google\n",
      "24 days ago\n",
      "Running\n",
      "17\n",
      "Path Foundation Demo\n",
      "🔬\n",
      "Access pathology images for medical reference\n",
      "google\n",
      "Apr 1\n",
      "Running\n",
      "14\n",
      "CXR Foundation Demo\n",
      "🩻\n",
      "Demo usage of the CXR Foundation model embeddings\n",
      "google\n",
      "Mar 28\n",
      "Running\n",
      "45\n",
      "Compare Siglip1 Siglip2\n",
      "🚀\n",
      "Compare SigLIP1 and SigLIP2 on zero shot classification\n",
      "google\n",
      "Feb 20\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "91\n",
      "Paligemma2 Mix\n",
      "🌖\n",
      "Generate text or segment objects from an image\n",
      "google\n",
      "Feb 19\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.98k\n",
      "Stable Diffusion XL on TPUv5e\n",
      "🏋\n",
      "Generate images from text prompts with various styles\n",
      "google\n",
      "Jan 28\n",
      "Expand\n",
      "\t\t\t\t\t\t\t9\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "1,000\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "google/videoprism\n",
      "Updated\n",
      "2 days ago\n",
      "•\n",
      "7\n",
      "google/gemma-3n-E4B-it-litert-lm-preview\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "10\n",
      "google/gemma-3n-E2B-it-litert-lm-preview\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "6 days ago\n",
      "•\n",
      "32\n",
      "google/medgemma-27b-text-it\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "47.3k\n",
      "•\n",
      "249\n",
      "google/gemma-3n-E4B-it-litert-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "22 days ago\n",
      "•\n",
      "1.13k\n",
      "google/svq\n",
      "Updated\n",
      "25 days ago\n",
      "•\n",
      "2\n",
      "google/medgemma-4b-pt\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "26 days ago\n",
      "•\n",
      "6.59k\n",
      "•\n",
      "89\n",
      "google/medgemma-4b-it\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "26 days ago\n",
      "•\n",
      "87.3k\n",
      "•\n",
      "382\n",
      "google/gemma-3n-E2B-it-litert-preview\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "27 days ago\n",
      "•\n",
      "382\n",
      "google/gemma-scope-2b-pt-transcoders\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "9\n",
      "Expand\n",
      "\t\t\t\t\t\t\t1,000\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "55\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "google/DOCCI-Critique\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "10.2k\n",
      "•\n",
      "1\n",
      "google/svq\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "322\n",
      "•\n",
      "4\n",
      "google/wmt24pp\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 13\n",
      "•\n",
      "54.9k\n",
      "•\n",
      "3.29k\n",
      "•\n",
      "43\n",
      "google/smol\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 3\n",
      "•\n",
      "811k\n",
      "•\n",
      "1.6k\n",
      "•\n",
      "58\n",
      "google/wmt24pp-images\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 24\n",
      "•\n",
      "170\n",
      "•\n",
      "39\n",
      "•\n",
      "4\n",
      "google/spiqa\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 8\n",
      "•\n",
      "666\n",
      "•\n",
      "418\n",
      "•\n",
      "37\n",
      "google/FACTS-grounding-public\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Dec 19, 2024\n",
      "•\n",
      "868\n",
      "•\n",
      "128\n",
      "•\n",
      "28\n",
      "google/frames-benchmark\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 15, 2024\n",
      "•\n",
      "824\n",
      "•\n",
      "2.73k\n",
      "•\n",
      "210\n",
      "google/flame-collection\n",
      "Updated\n",
      "Sep 23, 2024\n",
      "•\n",
      "31\n",
      "•\n",
      "1\n",
      "google/xtreme_s\n",
      "Updated\n",
      "Sep 10, 2024\n",
      "•\n",
      "6.82k\n",
      "•\n",
      "62\n",
      "Expand\n",
      "\t\t\t\t\t\t\t55\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/Intel\n",
      "Webpage Title:\n",
      "Intel (Intel)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Intel\n",
      "company\n",
      "Verified\n",
      "Activity Feed\n",
      "Request to join this org\n",
      "Follow\n",
      "2,637\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "n1ck-guo\n",
      "updated\n",
      "a dataset\n",
      "about 1 hour ago\n",
      "Intel/dynamic_model_information\n",
      "weiweiz1\n",
      "updated\n",
      "a model\n",
      "1 day ago\n",
      "Intel/DeepSeek-R1-0528-int4-asym-awq-inc\n",
      "weiweiz1\n",
      "updated\n",
      "a model\n",
      "1 day ago\n",
      "Intel/DeepSeek-R1-0528-int4-sym-gptq-inc\n",
      "View all activity\n",
      "Articles\n",
      "Introducing AutoRound: Intel’s Advanced Quantization for LLMs and VLMs\n",
      "Apr 29\n",
      "•\n",
      "33\n",
      "Introducing HELMET\n",
      "Apr 16\n",
      "•\n",
      "31\n",
      "Accelerating LLM Inference with TGI on Intel Gaudi\n",
      "Mar 28\n",
      "•\n",
      "13\n",
      "Benchmarking Language Model Performance on 5th Gen Xeon at GCP\n",
      "Dec 17, 2024\n",
      "•\n",
      "5\n",
      "Universal Assisted Generation: Faster Decoding with Any Assistant Model\n",
      "Oct 29, 2024\n",
      "•\n",
      "55\n",
      "Faster Assisted Generation with Dynamic Speculation\n",
      "Oct 8, 2024\n",
      "•\n",
      "48\n",
      "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI\n",
      "Sep 20, 2024\n",
      "•\n",
      "23\n",
      "Accelerating Protein Language Model ProtST on Intel Gaudi 2\n",
      "Jul 3, 2024\n",
      "•\n",
      "2\n",
      "Faster assisted generation support for Intel Gaudi\n",
      "Jun 4, 2024\n",
      "•\n",
      "3\n",
      "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon\n",
      "May 9, 2024\n",
      "•\n",
      "12\n",
      "Blazing Fast SetFit Inference with 🤗 Optimum Intel on Xeon\n",
      "Apr 3, 2024\n",
      "•\n",
      "11\n",
      "Team members\n",
      "2024\n",
      "+1990\n",
      "+1977\n",
      "+1956\n",
      "+1946\n",
      "+1926\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Intel on Hugging Face\n",
      "Intel and Hugging Face are building powerful optimization tools to accelerate training and inference with Hugging Face libraries.\n",
      "Get started on Intel architecture with Optimum Intel and Optimum Habana\n",
      "To get started with Hugging Face Transformers software on Intel, visit the resources listed below.\n",
      "Optimum Intel\n",
      "- To deploy on Intel® Xeon, Intel® Max Series GPU, and Intel® Core Ultra, check out\n",
      "optimum-intel\n",
      ", the interface between Intel architectures and the 🤗 Transformers and Diffusers libraries. You can use these backends:\n",
      "Backend\n",
      "Installation\n",
      "OpenVINO™\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[openvino]\"\n",
      "Intel® Extension for PyTorch*\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[ipex]\"\n",
      "Intel® Neural Compressor\n",
      "pip install --upgrade --upgrade-strategy eager \"optimum[neural-compressor]\"\n",
      "Optimum Habana\n",
      "- To deploy on Intel® Gaudi® AI accelerators, check out\n",
      "optimum-habana\n",
      ", the interface between Gaudi and the 🤗 Transformers and Diffusers libraries. To install the latest stable release:\n",
      "pip install --upgrade-strategy eager optimum[habana]\n",
      "Ways to get involved\n",
      "Check out the\n",
      "Intel® Tiber™ AI Cloud\n",
      "to run your latest GenAI or LLM workload on Intel architecture.\n",
      "Want to share your model fine-tuned on Intel architecture? And for more detailed deployment tips and sample code, please visit the \"Deployment Tips\" tab from the\n",
      "Powered-by-Intel LLM Leaderboard\n",
      ".\n",
      "Join us on the\n",
      "Intel DevHub Discord\n",
      "to ask questions and interact with our AI developer community.\n",
      "Collections\n",
      "44\n",
      "AI PC: Text Generation\n",
      "Text generation LLMs that have been validated to run on the AI PC Intel® Core™ Ultra CPU and iGPU.\n",
      "OpenVINO/Mixtral-8x7B-Instruct-v0.1-int8-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "153\n",
      "•\n",
      "4\n",
      "OpenVINO/mixtral-8x7b-instruct-v0.1-int4-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "81\n",
      "•\n",
      "4\n",
      "OpenVINO/phi-2-fp16-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Nov 5, 2024\n",
      "•\n",
      "144\n",
      "•\n",
      "1\n",
      "OpenVINO/phi-2-int8-ov\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 29, 2024\n",
      "•\n",
      "61\n",
      "AI PC: Text-to-Image\n",
      "Text-to-image models that have been validated to run on the AI PC Intel® Core™ Ultra CPU and iGPU.\n",
      "OpenVINO/stable-diffusion-v1-5-fp16-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "2\n",
      "OpenVINO/stable-diffusion-v1-5-int8-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "4\n",
      "OpenVINO/LCM_Dreamshaper_v7-fp16-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "3\n",
      "OpenVINO/LCM_Dreamshaper_v7-int8-ov\n",
      "Updated\n",
      "Feb 11\n",
      "•\n",
      "3\n",
      "Expand 44 collections\n",
      "spaces\n",
      "18\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "4\n",
      "Synthetic Data Generator\n",
      "⚗\n",
      "Create synthetic datasets for AI applications\n",
      "Intel\n",
      "Apr 6\n",
      "pinned\n",
      "Running\n",
      "7\n",
      "UnlearnDiffAtk Benchmark\n",
      "🥇\n",
      "Browse and filter AI model evaluation results\n",
      "Intel\n",
      "Feb 4\n",
      "pinned\n",
      "Running\n",
      "173\n",
      "Low-bit Quantized Open LLM Leaderboard\n",
      "🏆\n",
      "Track, rank and evaluate open LLMs and chatbots\n",
      "Intel\n",
      "Dec 23, 2024\n",
      "Running\n",
      "Preventative Healthcare with AutoGen\n",
      "🔥\n",
      "Using AI agents for preventative healthcare maintenance\n",
      "Intel\n",
      "5 days ago\n",
      "Running\n",
      "5\n",
      "Stock Trader\n",
      "📚\n",
      "Stock trading application\n",
      "Intel\n",
      "6 days ago\n",
      "Running\n",
      "VacAIgent\n",
      "🐨\n",
      "Let AI agents plan your next vacation!\n",
      "Intel\n",
      "6 days ago\n",
      "Expand\n",
      "\t\t\t\t\t\t\t18\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "232\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Intel/DeepSeek-R1-0528-int4-asym-awq-inc\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "10\n",
      "Intel/DeepSeek-R1-0528-int4-sym-gptq-inc\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "6\n",
      "Intel/DeepSeek-R1-0528-int2-mixed-sym-inc\n",
      "Updated\n",
      "1 day ago\n",
      "•\n",
      "1\n",
      "Intel/musicgen-static-openvino\n",
      "Text-to-Audio\n",
      "•\n",
      "Updated\n",
      "9 days ago\n",
      "•\n",
      "4\n",
      "Intel/deepfilternet-openvino\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "3\n",
      "Intel/versatile_audio_super_resolution_openvino\n",
      "Updated\n",
      "13 days ago\n",
      "•\n",
      "1\n",
      "Intel/DeepSeek-R1-0528-Qwen3-8B-int4-AutoRound-gptq-inc\n",
      "Updated\n",
      "16 days ago\n",
      "•\n",
      "1.79k\n",
      "•\n",
      "1\n",
      "Intel/DeepSeek-R1-0528-Qwen3-8B-int4-AutoRound-awq-inc\n",
      "Updated\n",
      "16 days ago\n",
      "•\n",
      "2.08k\n",
      "•\n",
      "1\n",
      "Intel/DeepSeek-R1-0528-Qwen3-8B-int4-AutoRound-inc\n",
      "Updated\n",
      "16 days ago\n",
      "•\n",
      "101\n",
      "Intel/Qwen3-30B-A3B-int4-AutoRound-inc\n",
      "Updated\n",
      "21 days ago\n",
      "•\n",
      "1.27k\n",
      "Expand\n",
      "\t\t\t\t\t\t\t232\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "21\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Intel/dynamic_model_information\n",
      "Updated\n",
      "about 1 hour ago\n",
      "•\n",
      "442\n",
      "Intel/ld_requests\n",
      "Updated\n",
      "May 12\n",
      "•\n",
      "1.1k\n",
      "•\n",
      "3\n",
      "Intel/Uncovering_LVLM_Bias\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 6\n",
      "•\n",
      "54.5M\n",
      "•\n",
      "160\n",
      "Intel/NeuroComparatives\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Apr 22\n",
      "•\n",
      "8.71M\n",
      "•\n",
      "51\n",
      "Intel/AI-Peer-Review-Detection\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "51\n",
      "•\n",
      "1\n",
      "Intel/polite-guard\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jan 16\n",
      "•\n",
      "100k\n",
      "•\n",
      "462\n",
      "•\n",
      "12\n",
      "Intel/fivl-instruct\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Dec 18, 2024\n",
      "•\n",
      "1.22M\n",
      "•\n",
      "55\n",
      "Intel/Video_Summarization_For_Retail\n",
      "Updated\n",
      "Jul 8, 2024\n",
      "•\n",
      "14\n",
      "Intel/ld_results\n",
      "Updated\n",
      "Jun 6, 2024\n",
      "•\n",
      "96\n",
      "•\n",
      "1\n",
      "Intel/SocialCounterfactuals\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Mar 28, 2024\n",
      "•\n",
      "171k\n",
      "•\n",
      "2.93k\n",
      "•\n",
      "11\n",
      "Expand\n",
      "\t\t\t\t\t\t\t21\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/microsoft\n",
      "Webpage Title:\n",
      "microsoft (Microsoft)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Microsoft\n",
      "company\n",
      "Verified\n",
      "https://www.microsoft.com/en-us/research/\n",
      "microsoft\n",
      "Activity Feed\n",
      "Follow\n",
      "12,954\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "gugarosa\n",
      "updated\n",
      "a model\n",
      "3 days ago\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "gugarosa\n",
      "updated\n",
      "a model\n",
      "3 days ago\n",
      "microsoft/Phi-4-reasoning\n",
      "unilm\n",
      "authored\n",
      "a paper\n",
      "7 days ago\n",
      "Think Only When You Need with Large Hybrid-Reasoning Models\n",
      "View all activity\n",
      "Team members\n",
      "230\n",
      "+196\n",
      "+183\n",
      "+162\n",
      "+152\n",
      "+132\n",
      "Collections\n",
      "18\n",
      "Phi-4\n",
      "Phi-4 family of small language, multi-modal and reasoning models.\n",
      "microsoft/Phi-4-mini-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "May 1\n",
      "•\n",
      "21.3k\n",
      "•\n",
      "171\n",
      "microsoft/Phi-4-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "29.6k\n",
      "•\n",
      "185\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "12.4k\n",
      "•\n",
      "280\n",
      "microsoft/Phi-4-multimodal-instruct\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "May 1\n",
      "•\n",
      "529k\n",
      "•\n",
      "1.42k\n",
      "Phi-3\n",
      "Phi-3 family of small language and multi-modal models. Language models are available in short- and long-context lengths.\n",
      "microsoft/Phi-3.5-mini-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 2\n",
      "•\n",
      "276k\n",
      "•\n",
      "•\n",
      "876\n",
      "microsoft/Phi-3.5-MoE-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Mar 7\n",
      "•\n",
      "35.6k\n",
      "•\n",
      "558\n",
      "microsoft/Phi-3.5-vision-instruct\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "Sep 26, 2024\n",
      "•\n",
      "1.04M\n",
      "•\n",
      "687\n",
      "microsoft/Phi-3-mini-4k-instruct\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Sep 20, 2024\n",
      "•\n",
      "602k\n",
      "•\n",
      "•\n",
      "1.21k\n",
      "Expand 18 collections\n",
      "spaces\n",
      "24\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "pinned\n",
      "Running\n",
      "12\n",
      "MageBench Leaderboard\n",
      "🥇\n",
      "This is a leaderboard for magebench\n",
      "microsoft\n",
      "Jan 17\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "4.76k\n",
      "TRELLIS\n",
      "🏢\n",
      "Scalable and Versatile 3D Generation from images\n",
      "microsoft\n",
      "12 days ago\n",
      "Running\n",
      "40\n",
      "Phi 4 Mini\n",
      "🌍\n",
      "Demos for Phi-4-mini-instruct model\n",
      "microsoft\n",
      "27 days ago\n",
      "Running\n",
      "33\n",
      "PhineSpeechTranslator\n",
      "👀\n",
      "Break the language barrier\n",
      "microsoft\n",
      "Apr 9\n",
      "Build error\n",
      "8\n",
      "StoriesComeAlive\n",
      "🏆\n",
      "Transform handwritten moments into spoken memories\n",
      "microsoft\n",
      "Apr 9\n",
      "Build error\n",
      "29\n",
      "ThoughtsOrganizer\n",
      "🔥\n",
      "Transform your spoken thoughts into organized insights\n",
      "microsoft\n",
      "Apr 9\n",
      "Expand\n",
      "\t\t\t\t\t\t\t24\n",
      "\t\t\t\t\t\t\t\tspaces\n",
      "models\n",
      "390\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "microsoft/Phi-4-reasoning-plus\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "12.4k\n",
      "•\n",
      "280\n",
      "microsoft/Phi-4-reasoning\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "3 days ago\n",
      "•\n",
      "29.6k\n",
      "•\n",
      "185\n",
      "microsoft/Phi-4-multimodal-instruct-onnx\n",
      "Automatic Speech Recognition\n",
      "•\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "98\n",
      "•\n",
      "71\n",
      "microsoft/Phi-3.5-vision-instruct-onnx\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "27\n",
      "•\n",
      "11\n",
      "microsoft/Phi-3-vision-128k-instruct-onnx\n",
      "Updated\n",
      "4 days ago\n",
      "•\n",
      "33\n",
      "•\n",
      "6\n",
      "microsoft/Phi-4-reasoning-plus-onnx\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "7\n",
      "microsoft/Phi-4-reasoning-onnx\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "7\n",
      "microsoft/Phi-4-mini-reasoning-onnx\n",
      "Updated\n",
      "5 days ago\n",
      "•\n",
      "10\n",
      "microsoft/UniGenX\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "6\n",
      "microsoft/GUI-Actor-Verifier-2B\n",
      "Image-Text-to-Text\n",
      "•\n",
      "Updated\n",
      "7 days ago\n",
      "•\n",
      "126\n",
      "•\n",
      "10\n",
      "Expand\n",
      "\t\t\t\t\t\t\t390\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "61\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "microsoft/sat\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "960\n",
      "•\n",
      "193\n",
      "•\n",
      "1\n",
      "microsoft/tsp\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "14 days ago\n",
      "•\n",
      "800\n",
      "•\n",
      "201\n",
      "•\n",
      "1\n",
      "microsoft/mediflow\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "17 days ago\n",
      "•\n",
      "1.84M\n",
      "•\n",
      "3.65k\n",
      "•\n",
      "34\n",
      "microsoft/Eureka-Bench-Logs\n",
      "Updated\n",
      "20 days ago\n",
      "•\n",
      "2.03k\n",
      "•\n",
      "6\n",
      "microsoft/rifts\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "21 days ago\n",
      "•\n",
      "1.74k\n",
      "•\n",
      "113\n",
      "•\n",
      "4\n",
      "microsoft/templatic_generation_tasks\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "28 days ago\n",
      "•\n",
      "6.1M\n",
      "•\n",
      "253\n",
      "•\n",
      "1\n",
      "microsoft/llmail-inject-challenge\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 16\n",
      "•\n",
      "462k\n",
      "•\n",
      "306\n",
      "•\n",
      "12\n",
      "microsoft/lost_in_conversation\n",
      "Updated\n",
      "May 9\n",
      "•\n",
      "220\n",
      "•\n",
      "12\n",
      "microsoft/CoSAlign-Test\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 5\n",
      "•\n",
      "3.2k\n",
      "•\n",
      "150\n",
      "•\n",
      "2\n",
      "microsoft/CoSAlign-Train\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "May 5\n",
      "•\n",
      "125k\n",
      "•\n",
      "96\n",
      "Expand\n",
      "\t\t\t\t\t\t\t61\n",
      "\t\t\t\t\t\t\t\tdatasets\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/grammarly\n",
      "Webpage Title:\n",
      "grammarly (Grammarly)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Grammarly\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://www.grammarly.com/\n",
      "grammarly\n",
      "Activity Feed\n",
      "Follow\n",
      "164\n",
      "AI & ML interests\n",
      "None defined yet.\n",
      "Recent Activity\n",
      "machineteacher\n",
      "authored\n",
      "a paper\n",
      "about 2 months ago\n",
      "Toward Evaluative Thinking: Meta Policy Optimization with Evolving\n",
      "  Reward Models\n",
      "machineteacher\n",
      "updated\n",
      "a model\n",
      "4 months ago\n",
      "grammarly/spivavtor-xxl\n",
      "machineteacher\n",
      "updated\n",
      "a model\n",
      "4 months ago\n",
      "grammarly/spivavtor-large\n",
      "View all activity\n",
      "Team members\n",
      "49\n",
      "+15\n",
      "+2\n",
      "Collections\n",
      "3\n",
      "CoEdIT\n",
      "Collection of the publicly available CoEdIT dataset and instruction-tuned models for text editing.\n",
      "CoEdIT: Text Editing by Task-Specific Instruction Tuning\n",
      "Paper\n",
      "•\n",
      "2305.09857\n",
      "•\n",
      "Published\n",
      "May 17, 2023\n",
      "•\n",
      "7\n",
      "grammarly/coedit-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "5.01k\n",
      "•\n",
      "142\n",
      "grammarly/coedit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "303\n",
      "•\n",
      "9\n",
      "grammarly/coedit-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "99\n",
      "•\n",
      "32\n",
      "mEdIT\n",
      "Collection of the publicly available mEdIT dataset and instruction-tuned models for multilingual text revision.\n",
      "grammarly/medit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "113k\n",
      "•\n",
      "81\n",
      "•\n",
      "13\n",
      "grammarly/medit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "5\n",
      "grammarly/medit-xxl\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "11\n",
      "Expand 3 collections\n",
      "models\n",
      "10\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "grammarly/spivavtor-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "46\n",
      "•\n",
      "4\n",
      "grammarly/spivavtor-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "60\n",
      "•\n",
      "9\n",
      "grammarly/medit-xxl\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "11\n",
      "grammarly/medit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Jun 28, 2024\n",
      "•\n",
      "5\n",
      "grammarly/coedit-xxl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "99\n",
      "•\n",
      "32\n",
      "grammarly/coedit-xl\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "303\n",
      "•\n",
      "9\n",
      "grammarly/coedit-large\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Apr 28, 2024\n",
      "•\n",
      "5.01k\n",
      "•\n",
      "142\n",
      "grammarly/coedit-xl-composite\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 5, 2023\n",
      "•\n",
      "65\n",
      "•\n",
      "19\n",
      "grammarly/pseudonymization-seq2seq\n",
      "Text2Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 31, 2023\n",
      "•\n",
      "5\n",
      "grammarly/detexd-roberta-base\n",
      "Text Classification\n",
      "•\n",
      "Updated\n",
      "Jul 10, 2023\n",
      "•\n",
      "34\n",
      "•\n",
      "10\n",
      "datasets\n",
      "5\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "grammarly/spivavtor\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 5\n",
      "•\n",
      "69.8k\n",
      "•\n",
      "88\n",
      "•\n",
      "3\n",
      "grammarly/medit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "113k\n",
      "•\n",
      "81\n",
      "•\n",
      "13\n",
      "grammarly/coedit\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Oct 21, 2023\n",
      "•\n",
      "70.8k\n",
      "•\n",
      "1.03k\n",
      "•\n",
      "75\n",
      "grammarly/pseudonymization-data\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Aug 23, 2023\n",
      "•\n",
      "390\n",
      "•\n",
      "1\n",
      "grammarly/detexd-benchmark\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 10, 2023\n",
      "•\n",
      "1.02k\n",
      "•\n",
      "46\n",
      "•\n",
      "2\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "Link: https://huggingface.co/Writer\n",
      "Webpage Title:\n",
      "Writer (Writer)\n",
      "Webpage Contents:\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "Verified\n",
      "https://writer.com/\n",
      "Get_Writer\n",
      "writer\n",
      "Activity Feed\n",
      "Follow\n",
      "296\n",
      "AI & ML interests\n",
      "AGI, LLMs, Knowledge Graph, Palmyra, Domain Specific LLM\n",
      "Recent Activity\n",
      "dmytro-writer\n",
      "authored\n",
      "a paper\n",
      "12 days ago\n",
      "Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning\n",
      "shelly-writer\n",
      "authored\n",
      "a paper\n",
      "12 days ago\n",
      "Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning\n",
      "wassemgtk\n",
      "authored\n",
      "a paper\n",
      "13 days ago\n",
      "Reflect, Retry, Reward: Self-Improving LLMs via Reinforcement Learning\n",
      "View all activity\n",
      "Team members\n",
      "148\n",
      "+114\n",
      "+101\n",
      "+80\n",
      "+70\n",
      "+50\n",
      "Organization Card\n",
      "Community\n",
      "About org cards\n",
      "Transform work with full-stack generative AI\n",
      "Build generative AI into any business process with the secure enterprise platform.\n",
      "Collections\n",
      "2\n",
      "Palmyra (apache 2.0 license)\n",
      "Writer/palmyra-small\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Sep 1, 2023\n",
      "•\n",
      "1.37k\n",
      "•\n",
      "20\n",
      "Writer/palmyra-20b-chat\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 17, 2024\n",
      "•\n",
      "354\n",
      "•\n",
      "11\n",
      "Writer/palmyra-med-20b\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Aug 17, 2024\n",
      "•\n",
      "4.48k\n",
      "•\n",
      "34\n",
      "Writer/palmyra-base\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 24, 2024\n",
      "•\n",
      "2.91k\n",
      "•\n",
      "44\n",
      "Palmyra (Writer license)\n",
      "Palmyra LLMs under Writer license https://writer.com/legal/open-model-license/\n",
      "Writer/Palmyra-Med-70B-32K\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "40\n",
      "•\n",
      "111\n",
      "Writer/Palmyra-Med-70B\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Oct 1, 2024\n",
      "•\n",
      "13\n",
      "•\n",
      "81\n",
      "spaces\n",
      "4\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Running\n",
      "GRPO Any Model\n",
      "🌍\n",
      "Train and generate text using GRPO\n",
      "Writer\n",
      "22 days ago\n",
      "Running\n",
      "9\n",
      "Financial LLM Performance Leaderboard\n",
      "📈\n",
      "Expect the Unexpected: FailSafe Long Context QA for Finance\n",
      "Writer\n",
      "Feb 19\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "6\n",
      "Token Counter\n",
      "📈\n",
      "Count tokens for different models\n",
      "Writer\n",
      "Nov 1, 2024\n",
      "Running\n",
      "5\n",
      "Paste To Markdown\n",
      "👁\n",
      "Convert text to Markdown\n",
      "Writer\n",
      "May 12, 2023\n",
      "models\n",
      "21\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Writer/colab\n",
      "Updated\n",
      "18 days ago\n",
      "•\n",
      "2\n",
      "Writer/Palmyra-X-4.3-73B\n",
      "Updated\n",
      "27 days ago\n",
      "•\n",
      "2.32k\n",
      "•\n",
      "1\n",
      "Writer/Palmyra-local-1_7B\n",
      "Updated\n",
      "Apr 7\n",
      "•\n",
      "165\n",
      "•\n",
      "1\n",
      "Writer/palmyra-large\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Feb 25\n",
      "•\n",
      "378\n",
      "•\n",
      "23\n",
      "Writer/palmyra-vision-dummy-weights\n",
      "Updated\n",
      "Jan 28\n",
      "Writer/bdiff-test\n",
      "Updated\n",
      "Jan 17\n",
      "Writer/palmyra-base\n",
      "Text Generation\n",
      "•\n",
      "Updated\n",
      "Dec 24, 2024\n",
      "•\n",
      "2.91k\n",
      "•\n",
      "44\n",
      "Writer/palmyra-creative-dummy-weights\n",
      "Updated\n",
      "Dec 18, 2024\n",
      "Writer/palmyra-x-4.3-long-cite\n",
      "Updated\n",
      "Dec 13, 2024\n",
      "Writer/palmyra-x-004-dummy-weights\n",
      "Updated\n",
      "Dec 6, 2024\n",
      "Expand\n",
      "\t\t\t\t\t\t\t21\n",
      "\t\t\t\t\t\t\t\tmodels\n",
      "datasets\n",
      "6\n",
      "Sort: \n",
      "\t\tRecently updated\n",
      "Writer/FailSafeQA\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Feb 13\n",
      "•\n",
      "220\n",
      "•\n",
      "229\n",
      "•\n",
      "9\n",
      "Writer/writing-in-the-margins-multihoprag\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Sep 5, 2024\n",
      "•\n",
      "1k\n",
      "•\n",
      "23\n",
      "Writer/TinyStoriesInstruct-v0-32k-0.2\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 13, 2024\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "109\n",
      "•\n",
      "3\n",
      "Writer/TinyStoriesInstruct-v0-32k-0.1\n",
      "Viewer\n",
      "•\n",
      "Updated\n",
      "Jul 13, 2024\n",
      "•\n",
      "15.7k\n",
      "•\n",
      "41\n",
      "Writer/omniact\n",
      "Updated\n",
      "Apr 29, 2024\n",
      "•\n",
      "579\n",
      "•\n",
      "36\n",
      "Writer/Palmyra-instract-30\n",
      "Preview\n",
      "•\n",
      "Updated\n",
      "Sep 30, 2023\n",
      "•\n",
      "5\n",
      "•\n",
      "1\n",
      "System theme\n",
      "Company\n",
      "TOS\n",
      "Privacy\n",
      "About\n",
      "Jobs\n",
      "Website\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Pricing\n",
      "Docs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_all_details(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76a5d140-c4dc-4dfe-9ded-2f09e50be5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\"|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "997dea25-b686-43ef-98ab-cc3d12ca44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47a84ed3-ffa3-4981-8b99-3bba404d4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = requests.post('http://localhost:11434/api/generate',\n",
    "                       json={\n",
    "                           'model': 'llama3.2',  # or whatever model you have\n",
    "                           'prompt': f\"System: {system_prompt}\\n\\nUser: {get_brochure_user_prompt(company_name, url)}\",\n",
    "                           'stream': False\n",
    "                       })\n",
    "    result = response.json()['response']\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e38b09d-7e57-4ad1-832b-4d58f2a2293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': ['https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/docs', 'https://huggingface.co/enterprise', 'https://huggingface.co/pricing', 'https://huggingface.co/allenai', 'https://huggingface.co/facebook', 'https://huggingface.co/amazon', 'https://huggingface.co/google', 'https://huggingface.co/Intel', 'https://huggingface.co/microsoft', 'https://huggingface.co/grammarly', 'https://huggingface.co/Writer', 'https://huggingface.co/docs/transformers', 'https://huggingface.co/docs/diffusers', 'https://huggingface.co/docs/safetensors', 'https://huggingface.co/docs/huggingface_hub', 'https://huggingface.co/docs/tokenizers', 'https://huggingface.co/docs/trl', 'https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/changelog']}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "======================\n",
       "\n",
       "Welcome to Hugging Face, the AI community building the future.\n",
       "\n",
       "## About Us\n",
       "----------------\n",
       "\n",
       "Hugging Face is a collaboration platform for machine learning that enables creators to host and collaborate on unlimited public models, datasets, and applications. Our mission is to make AI accessible to everyone.\n",
       "\n",
       "## Community\n",
       "-------------\n",
       "\n",
       "Our community of over 50,000 organizations uses Hugging Face to build and deploy AI models. We're proud to be used by top companies like Meta, Google, Amazon, Intel, Microsoft, and Grammarly.\n",
       "\n",
       "## Products\n",
       "------------\n",
       "\n",
       "* **Models**: Browse 1M+ pre-trained models for text, image, video, audio, or 3D applications.\n",
       "* **Datasets**: Access 250k+ public datasets for any ML task.\n",
       "* **Spaces**: Collaborate on unlimited public models, datasets, and applications.\n",
       "\n",
       "## Culture\n",
       "---------\n",
       "\n",
       "Our culture is built around open-source values, community engagement, and innovation. We believe in making AI accessible to everyone and building a platform that fosters collaboration and creativity.\n",
       "\n",
       "### Key Values\n",
       "\n",
       "* **Open-source**: We're committed to open-source software and data.\n",
       "* **Community-driven**: Our platform is built by and for the machine learning community.\n",
       "* **Innovation**: We strive to innovate and push the boundaries of what's possible with AI.\n",
       "\n",
       "## Careers\n",
       "---------\n",
       "\n",
       "Ready to join our team? Check out our [job openings](https://huggingface.co/jobs).\n",
       "\n",
       "### Why Work at Hugging Face?\n",
       "\n",
       "* **Collaborative environment**: Join a community of passionate machine learning enthusiasts.\n",
       "* **Innovative work**: Be part of building the future of AI and making a real impact.\n",
       "* **Professional development**: Grow your skills and expertise in the latest ML trends.\n",
       "\n",
       "## Resources\n",
       "------------\n",
       "\n",
       "* [Documentation](https://huggingface.co/docs)\n",
       "* [Blog](https://huggingface.co/blog)\n",
       "* [GitHub](https://github.com/huggingface)\n",
       "\n",
       "Join us on our mission to build a better future with AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16e8e0f1-9572-4e23-b2f0-115baf903965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally - a minor improvement\n",
    "#With a small adjustment, we can change this so that the results stream back from OpenAI, with the familiar typewriter animation\n",
    "def stream_brochure(company_name, url):\n",
    "    r = requests.post('http://localhost:11434/api/generate',\n",
    "                     json={\n",
    "                         'model': 'llama3.2',\n",
    "                         'prompt': f\"System: {system_prompt}\\n\\nUser: {get_brochure_user_prompt(company_name, url)}\",\n",
    "                         'stream': True\n",
    "                     }, stream=True)\n",
    "    \n",
    "    result = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for line in r.iter_lines():\n",
    "        if line:\n",
    "            chunk = json.loads(line)\n",
    "            if 'response' in chunk:\n",
    "                result += chunk['response']\n",
    "                display_handle.update(Markdown(result.replace(\"```\", \"\").replace(\"markdown\", \"\")))\n",
    "            if chunk.get('done'):\n",
    "                break\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7eef47f4-267d-4268-8225-b9cda855fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found links: {'links': ['https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/docs', 'https://huggingface.co/enterprise', 'https://huggingface.co/pricing', 'https://huggingface.co/allenai', 'https://huggingface.co/facebook', 'https://huggingface.co/amazon', 'https://huggingface.co/google', 'https://huggingface.co/Intel', 'https://huggingface.co/microsoft', 'https://huggingface.co/grammarly', 'https://huggingface.co/Writer', 'https://huggingface.co/docs/transformers', 'https://huggingface.co/docs/diffusers', 'https://huggingface.co/docs/safetensors', 'https://huggingface.co/docs/huggingface_hub', 'https://huggingface.co/docs/tokenizers', 'https://huggingface.co/docs/trl', 'https://huggingface.co/models', 'https://huggingface.co/datasets', 'https://huggingface.co/spaces', 'https://huggingface.co/changelog', 'https://endpoints.huggingface.co', 'https://discuss.huggingface.co', 'https://status.huggingface.co', 'https://github.com/huggingface', 'https://twitter.com/huggingface', 'https://www.linkedin.com/company/huggingface/']}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face Brochure\n",
       "\n",
       "## About Us\n",
       "\n",
       "Hugging Face is a leading open-source platform for natural language processing (NLP) and machine learning (ML). Our mission is to build the future of AI by creating a collaborative community that explores, develops, and deploys cutting-edge ML technologies.\n",
       "\n",
       "## Our Culture\n",
       "\n",
       "At Hugging Face, we value collaboration, innovation, and diversity. Our culture is centered around the idea of \"Open Research\" - where everyone can contribute, share, and learn from each other's work. We believe in fostering a community-driven approach to AI development, ensuring that our platform remains accessible, transparent, and inclusive.\n",
       "\n",
       "## Customers\n",
       "\n",
       "We serve a wide range of customers across various industries, including:\n",
       "\n",
       "*   **Companies**: Meta, Amazon, Google, Intel, Microsoft, Grammarly, Writer\n",
       "*   **Non-Profits**: AI2\n",
       "*   **Government Agencies**: (Not specified)\n",
       "*   **Academia**: (Not specified)\n",
       "\n",
       "## Careers\n",
       "\n",
       "If you're passionate about AI and want to contribute to a growing community of researchers and developers, we invite you to explore our job opportunities:\n",
       "\n",
       "*   [Jobs](https://huggingface.co/jobs)\n",
       "*   [Internships](https://huggingface.co/internships)\n",
       "\n",
       "We also offer various resources for learning and development, including:\n",
       "\n",
       "*   **Documentation**: <https://huggingface.co/docs>\n",
       "*   **Tutorials**: <https://huggingface.co/tutorials>\n",
       "*   **Blog**: <https://huggingface.co/blog>\n",
       "\n",
       "## Products\n",
       "\n",
       "Our flagship products include:\n",
       "\n",
       "*   **Hugging Face Hub**: A platform for hosting, sharing, and collaborating on ML models, datasets, and applications.\n",
       "*   **Transformers**: State-of-the-art ML library for PyTorch, TensorFlow, JAX, and more.\n",
       "*   **Diffusers**: State-of-the-art diffusion models in PyTorch.\n",
       "\n",
       "## Pricing\n",
       "\n",
       "We offer a range of pricing plans to suit your needs:\n",
       "\n",
       "*   **Compute**: Starting at $0.000001 per batch\n",
       "*   **Inference Endpoints**: Starting at $0.0001 per request"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'# Hugging Face Brochure\\n\\n## About Us\\n\\nHugging Face is a leading open-source platform for natural language processing (NLP) and machine learning (ML). Our mission is to build the future of AI by creating a collaborative community that explores, develops, and deploys cutting-edge ML technologies.\\n\\n## Our Culture\\n\\nAt Hugging Face, we value collaboration, innovation, and diversity. Our culture is centered around the idea of \"Open Research\" - where everyone can contribute, share, and learn from each other\\'s work. We believe in fostering a community-driven approach to AI development, ensuring that our platform remains accessible, transparent, and inclusive.\\n\\n## Customers\\n\\nWe serve a wide range of customers across various industries, including:\\n\\n*   **Companies**: Meta, Amazon, Google, Intel, Microsoft, Grammarly, Writer\\n*   **Non-Profits**: AI2\\n*   **Government Agencies**: (Not specified)\\n*   **Academia**: (Not specified)\\n\\n## Careers\\n\\nIf you\\'re passionate about AI and want to contribute to a growing community of researchers and developers, we invite you to explore our job opportunities:\\n\\n*   [Jobs](https://huggingface.co/jobs)\\n*   [Internships](https://huggingface.co/internships)\\n\\nWe also offer various resources for learning and development, including:\\n\\n*   **Documentation**: <https://huggingface.co/docs>\\n*   **Tutorials**: <https://huggingface.co/tutorials>\\n*   **Blog**: <https://huggingface.co/blog>\\n\\n## Products\\n\\nOur flagship products include:\\n\\n*   **Hugging Face Hub**: A platform for hosting, sharing, and collaborating on ML models, datasets, and applications.\\n*   **Transformers**: State-of-the-art ML library for PyTorch, TensorFlow, JAX, and more.\\n*   **Diffusers**: State-of-the-art diffusion models in PyTorch.\\n\\n## Pricing\\n\\nWe offer a range of pricing plans to suit your needs:\\n\\n*   **Compute**: Starting at $0.000001 per batch\\n*   **Inference Endpoints**: Starting at $0.0001 per request'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a0305-cb6e-450c-a53a-f5b6a68d14b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
